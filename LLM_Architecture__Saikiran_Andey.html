<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>LLM_Architecture__Saikiran_Andey</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,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);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '•';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.6.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        const { svg } = await mermaid.render(id, raw, el);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Step-1:-Creating-Tokens">Step 1: Creating Tokens<a class="anchor-link" href="#Step-1:-Creating-Tokens">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>The print command prints the total number of characters followed by the first 100
characters of this file for illustration purposes. </p></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">"the-verdict.txt"</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">"utf-8"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">raw_text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Total number of character:"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">raw_text</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">raw_text</span><span class="p">[:</span><span class="mi">99</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Total number of character: 20479
I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no 
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Our goal is to tokenize this 20,479-character short story into individual words and special
characters that we can then turn into embeddings for LLM training  </p></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Note that it's common to process millions of articles and hundreds of thousands of
books -- many gigabytes of text -- when working with LLMs. However, for educational
purposes, it's sufficient to work with smaller text samples like a single book to
illustrate the main ideas behind the text processing steps and to make it possible to
run it in reasonable time on consumer hardware. </p></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">"Hello, world. This, is a test."</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">'(\s)'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
The result is a list of individual words, whitespaces, and punctuation characters:
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Let's modify the regular expression splits on whitespaces (\s) and commas, and periods
([,.]):</p></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">result</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">'([,.]|\s)'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
We can see that the words and punctuation characters are now separate list entries just as
we wanted
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>A small remaining issue is that the list still includes whitespace characters. Optionally, we
can remove these redundant characters safely as follows:</p></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">result</span> <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">strip</span><span class="p">()]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">"Hello, world. Is this-- a test?"</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">'([,.:;?_!"()</span><span class="se">\'</span><span class="s1">]|--|\s)'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">result</span> <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">strip</span><span class="p">()]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Strip whitespace from each item and then filter out any empty strings.</span>
<span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">result</span> <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">strip</span><span class="p">()]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">"Hello, world. Is this-- a test?"</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">'([,.:;?_!"()</span><span class="se">\'</span><span class="s1">]|--|\s)'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">result</span> <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">strip</span><span class="p">()]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Now that we got a basic tokenizer working, let's apply it to Edith Wharton's entire short
story:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">preprocessed</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">'([,.:;?_!"()</span><span class="se">\'</span><span class="s1">]|--|\s)'</span><span class="p">,</span> <span class="n">raw_text</span><span class="p">)</span>
<span class="n">preprocessed</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">preprocessed</span> <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">strip</span><span class="p">()]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">preprocessed</span><span class="p">[:</span><span class="mi">30</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">preprocessed</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>4690
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Step-2:-Creating-Token-IDs">Step 2: Creating Token IDs<a class="anchor-link" href="#Step-2:-Creating-Token-IDs">¶</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">all_words</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">preprocessed</span><span class="p">))</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_words</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>1130
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>After determining that the vocabulary size is 1,130 via the above code, we create the
vocabulary and print its first 51 entries for illustration purposes:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="p">{</span><span class="n">token</span><span class="p">:</span><span class="n">integer</span> <span class="k">for</span> <span class="n">integer</span><span class="p">,</span><span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_words</span><span class="p">)}</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">50</span><span class="p">:</span>
        <span class="k">break</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>('!', 0)
('"', 1)
("'", 2)
('(', 3)
(')', 4)
(',', 5)
('--', 6)
('.', 7)
(':', 8)
(';', 9)
('?', 10)
('A', 11)
('Ah', 12)
('Among', 13)
('And', 14)
('Are', 15)
('Arrt', 16)
('As', 17)
('At', 18)
('Be', 19)
('Begin', 20)
('Burlington', 21)
('But', 22)
('By', 23)
('Carlo', 24)
('Chicago', 25)
('Claude', 26)
('Come', 27)
('Croft', 28)
('Destroyed', 29)
('Devonshire', 30)
('Don', 31)
('Dubarry', 32)
('Emperors', 33)
('Florence', 34)
('For', 35)
('Gallery', 36)
('Gideon', 37)
('Gisburn', 38)
('Gisburns', 39)
('Grafton', 40)
('Greek', 41)
('Grindle', 42)
('Grindles', 43)
('HAD', 44)
('Had', 45)
('Hang', 46)
('Has', 47)
('He', 48)
('Her', 49)
('Hermia', 50)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Later in this book, when we want to convert the outputs of an LLM from numbers back into
text, we also need a way to turn token IDs into text.</p>
<p>For this, we can create an inverse
version of the vocabulary that maps token IDs back to corresponding text tokens.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Step 1: Store the vocabulary as a class attribute for access in the encode and decode methods</p>
<p>Step 2: Create an inverse vocabulary that maps token IDs back to the original text tokens</p>
<p>Step 3: Process input text into token IDs</p>
<p>Step 4: Convert token IDs back into text</p>
<p>Step 5: Replace spaces before the specified punctuation</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">SimpleTokenizerV1</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">str_to_int</span> <span class="o">=</span> <span class="n">vocab</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">int_to_str</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span><span class="p">,</span><span class="n">i</span> <span class="ow">in</span> <span class="n">vocab</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="n">preprocessed</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">'([,.:;?_!"()</span><span class="se">\'</span><span class="s1">]|--|\s)'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

        <span class="n">preprocessed</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">item</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">preprocessed</span> <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="p">]</span>
        <span class="n">ids</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">str_to_int</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">preprocessed</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">ids</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ids</span><span class="p">):</span>
        <span class="n">text</span> <span class="o">=</span> <span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">int_to_str</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ids</span><span class="p">])</span>
        <span class="c1"># Replace spaces before the specified punctuations</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'\s+([,.?!"()</span><span class="se">\'</span><span class="s1">])'</span><span class="p">,</span> <span class="sa">r</span><span class="s1">'\1'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">text</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Let's instantiate a new tokenizer object from the SimpleTokenizerV1 class and tokenize a
passage from Edith Wharton's short story to try it out in practice:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">SimpleTokenizerV1</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">""""It's the last he painted, you know,"</span>
<span class="s2">           Mrs. Gisburn said with pardonable pride."""</span>
<span class="n">ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>The code above prints the following token IDs:
Next, let's see if we can turn these token IDs back into text using the decode method:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[16]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>'" It\' s the last he painted, you know," Mrs. Gisburn said with pardonable pride.'</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Based on the output above, we can see that the decode method successfully converted the
token IDs back into the original text.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>The problem is that the word "Hello" was not used in the The Verdict short story.</p>
<p>Hence, it
is not contained in the vocabulary.</p>
<p>This highlights the need to consider large and diverse
training sets to extend the vocabulary when working on LLMs.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="ADDING-SPECIAL-CONTEXT-TOKENS">ADDING SPECIAL CONTEXT TOKENS<a class="anchor-link" href="#ADDING-SPECIAL-CONTEXT-TOKENS">¶</a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>We can modify the tokenizer to use an &lt;|unk|&gt; token if it
encounters a word that is not part of the vocabulary.</p>
<p>Furthermore, we add a token between
unrelated texts.</p>
<p>For example, when training GPT-like LLMs on multiple independent
documents or books, it is common to insert a token before each document or book that
follows a previous text source</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [17]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">all_tokens</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">preprocessed</span><span class="p">)))</span>
<span class="n">all_tokens</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s2">"&lt;|endoftext|&gt;"</span><span class="p">,</span> <span class="s2">"&lt;|unk|&gt;"</span><span class="p">])</span>

<span class="n">vocab</span> <span class="o">=</span> <span class="p">{</span><span class="n">token</span><span class="p">:</span><span class="n">integer</span> <span class="k">for</span> <span class="n">integer</span><span class="p">,</span><span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_tokens</span><span class="p">)}</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[18]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>1132</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Based on the output of the print statement above, the new vocabulary size is 1132 (the
vocabulary size in the previous section was 1130).</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Step 1: Replace unknown words by &lt;|unk|&gt; tokens</p>
<p>Step 2: Replace spaces before the specified punctuations</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">SimpleTokenizerV2</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">str_to_int</span> <span class="o">=</span> <span class="n">vocab</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">int_to_str</span> <span class="o">=</span> <span class="p">{</span> <span class="n">i</span><span class="p">:</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span><span class="p">,</span><span class="n">i</span> <span class="ow">in</span> <span class="n">vocab</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="n">preprocessed</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">'([,.:;?_!"()</span><span class="se">\'</span><span class="s1">]|--|\s)'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
        <span class="n">preprocessed</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">preprocessed</span> <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">strip</span><span class="p">()]</span>
        <span class="n">preprocessed</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">item</span> <span class="k">if</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">str_to_int</span>
            <span class="k">else</span> <span class="s2">"&lt;|unk|&gt;"</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">preprocessed</span>
        <span class="p">]</span>

        <span class="n">ids</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">str_to_int</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">preprocessed</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">ids</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ids</span><span class="p">):</span>
        <span class="n">text</span> <span class="o">=</span> <span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">int_to_str</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ids</span><span class="p">])</span>
        <span class="c1"># Replace spaces before the specified punctuations</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'\s+([,.:;?!"()</span><span class="se">\'</span><span class="s1">])'</span><span class="p">,</span> <span class="sa">r</span><span class="s1">'\1'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">text</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">SimpleTokenizerV2</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>

<span class="n">text1</span> <span class="o">=</span> <span class="s2">"Hello, do you like tea?"</span>
<span class="n">text2</span> <span class="o">=</span> <span class="s2">"In the sunlit terraces of the palace."</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">" &lt;|endoftext|&gt; "</span><span class="o">.</span><span class="n">join</span><span class="p">((</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Hello, do you like tea? &lt;|endoftext|&gt; In the sunlit terraces of the palace.
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [21]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[21]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [22]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[22]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>'&lt;|unk|&gt;, do you like tea? &lt;|endoftext|&gt; In the sunlit terraces of the &lt;|unk|&gt;.'</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Based on comparing the de-tokenized text above with the original input text, we know that
the training dataset, Edith Wharton's short story The Verdict, did not contain the words
"Hello" and "palace."</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>So far, we have discussed tokenization as an essential step in processing text as input to
LLMs. Depending on the LLM, some researchers also consider additional special tokens such
as the following:</p>
<p>[BOS] (beginning of sequence): This token marks the start of a text. It
signifies to the LLM where a piece of content begins.</p>
<p>[EOS] (end of sequence): This token is positioned at the end of a text,
and is especially useful when concatenating multiple unrelated texts,
similar to &lt;|endoftext|&gt;. For instance, when combining two different
Wikipedia articles or books, the [EOS] token indicates where one article
ends and the next one begins.</p>
<p>[PAD] (padding): When training LLMs with batch sizes larger than one,
the batch might contain texts of varying lengths. To ensure all texts have
the same length, the shorter texts are extended or "padded" using the
[PAD] token, up to the length of the longest text in the batch.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Note that the tokenizer used for GPT models does not need any of these tokens mentioned
above but only uses an &lt;|endoftext|&gt; token for simplicity</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>the tokenizer used for GPT models also doesn't use an &lt;|unk|&gt; token for outof-vocabulary words. Instead, GPT models use a byte pair encoding tokenizer, which breaks
down words into subword units</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="BYTE-PAIR-ENCODING-(BPE)">BYTE PAIR ENCODING (BPE)<a class="anchor-link" href="#BYTE-PAIR-ENCODING-(BPE)">¶</a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>We implemented a simple tokenization scheme in the previous sections for illustration
purposes.</p>
<p>This section covers a more sophisticated tokenization scheme based on a concept
called byte pair encoding (BPE).</p>
<p>The BPE tokenizer covered in this section was used to train
LLMs such as GPT-2, GPT-3, and the original model used in ChatGPT.</p></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Since implementing BPE can be relatively complicated, we will use an existing Python
open-source library called tiktoken (<a href="https://github.com/openai/tiktoken">https://github.com/openai/tiktoken</a>).</p>
<p>This library implements
the BPE algorithm very efficiently based on source code in Rust.</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span><span class="w"> </span>pip3<span class="w"> </span>install<span class="w"> </span>tiktoken
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Requirement already satisfied: tiktoken in /opt/anaconda3/lib/python3.11/site-packages (0.8.0)
Requirement already satisfied: regex&gt;=2022.1.18 in /opt/anaconda3/lib/python3.11/site-packages (from tiktoken) (2023.10.3)
Requirement already satisfied: requests&gt;=2.26.0 in /opt/anaconda3/lib/python3.11/site-packages (from tiktoken) (2.31.0)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests&gt;=2.26.0-&gt;tiktoken) (2.0.4)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests&gt;=2.26.0-&gt;tiktoken) (3.4)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests&gt;=2.26.0-&gt;tiktoken) (2.0.7)
Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests&gt;=2.26.0-&gt;tiktoken) (2024.2.2)
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">importlib</span>
<span class="kn">import</span> <span class="nn">tiktoken</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"tiktoken version:"</span><span class="p">,</span> <span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">"tiktoken"</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tiktoken version: 0.8.0
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
Once installed, we can instantiate the BPE tokenizer from tiktoken as follows:</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
The usage of this tokenizer is similar to SimpleTokenizerV2 we implemented previously via
an encode method:</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [26]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">"Hello, do you like tea? &lt;|endoftext|&gt; In the sunlit terraces"</span>
     <span class="s2">"of someunknownPlace."</span>
<span class="p">)</span>

<span class="n">integers</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">allowed_special</span><span class="o">=</span><span class="p">{</span><span class="s2">"&lt;|endoftext|&gt;"</span><span class="p">})</span>

<span class="nb">print</span><span class="p">(</span><span class="n">integers</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>The code above prints the following token IDs:</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
We can then convert the token IDs back into text using the decode method, similar to our
SimpleTokenizerV2 earlier:</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [27]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">strings</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">integers</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">strings</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Hello, do you like tea? &lt;|endoftext|&gt; In the sunlit terracesof someunknownPlace.
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>We can make two noteworthy observations based on the token IDs and decoded text
above.</p>
<p>First, the &lt;|endoftext|&gt; token is assigned a relatively large token ID, namely,
50256.</p>
<p>In fact, the BPE tokenizer, which was used to train models such as GPT-2, GPT-3,
and the original model used in ChatGPT, has a total vocabulary size of 50,257, with
&lt;|endoftext|&gt; being assigned the largest token ID.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Second, the BPE tokenizer above encodes and decodes unknown words, such as
"someunknownPlace" correctly.</p>
<p>The BPE tokenizer can handle any unknown word. How does
it achieve this without using &lt;|unk|&gt; tokens?</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The algorithm underlying BPE breaks down words that aren't in its predefined vocabulary
into smaller subword units or even individual characters.</p>
<p>The enables it to handle out-ofvocabulary words.</p>
<p>So, thanks to the BPE algorithm, if the tokenizer encounters an
unfamiliar word during tokenization, it can represent it as a sequence of subword tokens or
characters</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><strong>Let us take another simple example to illustrate how the BPE tokenizer deals with unknown tokens</strong></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [28]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">integers</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">"Akwirw ier"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">integers</span><span class="p">)</span>

<span class="n">strings</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">integers</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">strings</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[33901, 86, 343, 86, 220, 959]
Akwirw ier
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [29]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tiktoken</span>

<span class="c1"># Initialize the encodings for GPT-2, GPT-3, and GPT-4</span>
<span class="n">encodings</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"gpt2"</span><span class="p">:</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">),</span>
    <span class="s2">"gpt3"</span><span class="p">:</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">"p50k_base"</span><span class="p">),</span>  <span class="c1"># Commonly associated with GPT-3 models</span>
    <span class="s2">"gpt4"</span><span class="p">:</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">"cl100k_base"</span><span class="p">)</span>  <span class="c1"># Used for GPT-4 and later versions</span>
<span class="p">}</span>

<span class="c1"># Get the vocabulary size for each encoding</span>
<span class="n">vocab_sizes</span> <span class="o">=</span> <span class="p">{</span><span class="n">model</span><span class="p">:</span> <span class="n">encoding</span><span class="o">.</span><span class="n">n_vocab</span> <span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">encoding</span> <span class="ow">in</span> <span class="n">encodings</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

<span class="c1"># Print the vocabulary sizes</span>
<span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">vocab_sizes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The vocabulary size for </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2"> is: </span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>The vocabulary size for GPT2 is: 50257
The vocabulary size for GPT3 is: 50281
The vocabulary size for GPT4 is: 100277
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="CREATING-INPUT-TARGET-PAIRS">CREATING INPUT-TARGET PAIRS<a class="anchor-link" href="#CREATING-INPUT-TARGET-PAIRS">¶</a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
In this section we implement a data loader that fetches the input-target pairs using a sliding window approach.</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [30]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">"the-verdict.txt"</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">"utf-8"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">raw_text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">enc_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">raw_text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">enc_text</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>5145
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Executing the code above will return 5145, the total number of tokens in the training set,
after applying the BPE tokenizer.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
Next, we remove the first 50 tokens from the dataset for demonstration purposes as it
results in a slightly more interesting text passage in the next steps:</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [31]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">enc_sample</span> <span class="o">=</span> <span class="n">enc_text</span><span class="p">[</span><span class="mi">50</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
One of the easiest and most intuitive ways to create the input-target pairs for the nextword prediction task is to create two variables, x and y, where x contains the input tokens
and y contains the targets, which are the inputs shifted by 1:</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
The context size determines how many tokens are included in the input
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [32]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">context_size</span> <span class="o">=</span> <span class="mi">4</span> <span class="c1">#length of the input</span>
<span class="c1">#The context_size of 4 means that the model is trained to look at a sequence of 4 words (or tokens)</span>
<span class="c1">#to predict the next word in the sequence.</span>
<span class="c1">#The input x is the first 4 tokens [1, 2, 3, 4], and the target y is the next 4 tokens [2, 3, 4, 5]</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">enc_sample</span><span class="p">[:</span><span class="n">context_size</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">enc_sample</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">context_size</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"x: </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"y:      </span><span class="si">{</span><span class="n">y</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>x: [290, 4920, 2241, 287]
y:      [4920, 2241, 287, 257]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
Processing the inputs along with the targets, which are the inputs shifted by one position,
we can then create the next-word prediction tasks as
follows:</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [33]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">context_size</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">enc_sample</span><span class="p">[:</span><span class="n">i</span><span class="p">]</span>
    <span class="n">desired</span> <span class="o">=</span> <span class="n">enc_sample</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="s2">"----&gt;"</span><span class="p">,</span> <span class="n">desired</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[290] ----&gt; 4920
[290, 4920] ----&gt; 2241
[290, 4920, 2241] ----&gt; 287
[290, 4920, 2241, 287] ----&gt; 257
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
Everything left of the arrow (----&gt;) refers to the input an LLM would receive, and the token
ID on the right side of the arrow represents the target token ID that the LLM is supposed to
predict.
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
For illustration purposes, let's repeat the previous code but convert the token IDs into
text:</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [34]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">context_size</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">enc_sample</span><span class="p">[:</span><span class="n">i</span><span class="p">]</span>
    <span class="n">desired</span> <span class="o">=</span> <span class="n">enc_sample</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">context</span><span class="p">),</span> <span class="s2">"----&gt;"</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">desired</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre> and ----&gt;  established
 and established ----&gt;  himself
 and established himself ----&gt;  in
 and established himself in ----&gt;  a
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>We've now created the input-target pairs that we can turn into use for the LLM training in
upcoming chapters.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>There's only one more task before we can turn the tokens into embeddings:implementing an efficient data loader that
iterates over the input dataset and returns the inputs and targets as PyTorch tensors, which
can be thought of as multidimensional arrays.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="IMPLEMENTING-A-DATA-LOADER">IMPLEMENTING A DATA LOADER<a class="anchor-link" href="#IMPLEMENTING-A-DATA-LOADER">¶</a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
For the efficient data loader implementation, we will use PyTorch's built-in Dataset and
DataLoader classes.</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Step 1: Tokenize the entire text</p>
<p>Step 2: Use a sliding window to chunk the book into overlapping sequences of max_length</p>
<p>Step 3: Return the total number of rows in the dataset</p>
<p>Step 4: Return a single row from the dataset</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [35]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>


<span class="k">class</span> <span class="nc">GPTDatasetV1</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">txt</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_ids</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Tokenize the entire text</span>
        <span class="n">token_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">txt</span><span class="p">,</span> <span class="n">allowed_special</span><span class="o">=</span><span class="p">{</span><span class="s2">"&lt;|endoftext|&gt;"</span><span class="p">})</span>

        <span class="c1"># Use a sliding window to chunk the book into overlapping sequences of max_length</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span> <span class="o">-</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
            <span class="n">input_chunk</span> <span class="o">=</span> <span class="n">token_ids</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">max_length</span><span class="p">]</span>
            <span class="n">target_chunk</span> <span class="o">=</span> <span class="n">token_ids</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">max_length</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_chunk</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">target_chunk</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_ids</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The GPTDatasetV1 class in listing 2.5 is based on the PyTorch Dataset class.</p>
<p>It defines how individual rows are fetched from the dataset.</p>
<p>Each row consists of a number of
token IDs (based on a max_length) assigned to an input_chunk tensor.</p>
<p>The target_chunk
tensor contains the corresponding targets.</p>
<p>I recommend reading on to see how the data
returned from this dataset looks like when we combine the dataset with a PyTorch
DataLoader -- this will bring additional intuition and clarity.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
The following code will use the GPTDatasetV1 to load the inputs in batches via a PyTorch
DataLoader:</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Step 1: Initialize the tokenizer</p>
<p>Step 2: Create dataset</p>
<p>Step 3: drop_last=True drops the last batch if it is shorter than the specified batch_size to prevent loss spikes
during training</p>
<p>Step 4: The number of CPU processes to use for preprocessing</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [36]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">create_dataloader_v1</span><span class="p">(</span><span class="n">txt</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                         <span class="n">stride</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="c1"># Initialize the tokenizer</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>

    <span class="c1"># Create dataset</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">GPTDatasetV1</span><span class="p">(</span><span class="n">txt</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>

    <span class="c1"># Create dataloader</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">dataloader</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Let's test the dataloader with a batch size of 1 for an LLM with a context size of 4,</p>
<p>This will develop an intuition of how the GPTDatasetV1 class and the
create_dataloader_v1 function work together: </p></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [37]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">"the-verdict.txt"</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">"utf-8"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">raw_text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Convert dataloader into a Python iterator to fetch the next entry via Python's built-in next() function</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [38]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"PyTorch version:"</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">create_dataloader_v1</span><span class="p">(</span>
    <span class="n">raw_text</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">data_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
<span class="n">first_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data_iter</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">first_batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>PyTorch version: 2.5.1
[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The first_batch variable contains two tensors: the first tensor stores the input token IDs,
and the second tensor stores the target token IDs.</p>
<p>Since the max_length is set to 4, each of the two tensors contains 4 token IDs.</p>
<p>Note that an input size of 4 is relatively small and only chosen for illustration purposes. It is common to train LLMs with input sizes of at least
256.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>To illustrate the meaning of stride=1, let's fetch another batch from this dataset: </p></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [39]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">second_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data_iter</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">second_batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>If we compare the first with the second batch, we can see that the second batch's token
IDs are shifted by one position compared to the first batch.</p>
<p>For example, the second ID in
the first batch's input is 367, which is the first ID of the second batch's input.</p>
<p>The stride
setting dictates the number of positions the inputs shift across batches, emulating a sliding
window approach</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Batch sizes of 1, such as we have sampled from the data loader so far, are useful for
illustration purposes.</p>
<p>If you have previous experience with deep learning, you may know
that small batch sizes require less memory during training but lead to more noisy model
updates.</p>
<p>Just like in regular deep learning, the batch size is a trade-off and hyperparameter
to experiment with when training LLMs.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Before we move on to the two final sections of this chapter that are focused on creating
the embedding vectors from the token IDs, let's have a brief look at how we can use the
data loader to sample with a batch size greater than 1: </p></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [40]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">dataloader</span> <span class="o">=</span> <span class="n">create_dataloader_v1</span><span class="p">(</span><span class="n">raw_text</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">data_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
<span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data_iter</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Inputs:</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Targets:</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Inputs:
 tensor([[   40,   367,  2885,  1464],
        [ 1807,  3619,   402,   271],
        [10899,  2138,   257,  7026],
        [15632,   438,  2016,   257],
        [  922,  5891,  1576,   438],
        [  568,   340,   373,   645],
        [ 1049,  5975,   284,   502],
        [  284,  3285,   326,    11]])

Targets:
 tensor([[  367,  2885,  1464,  1807],
        [ 3619,   402,   271, 10899],
        [ 2138,   257,  7026, 15632],
        [  438,  2016,   257,   922],
        [ 5891,  1576,   438,   568],
        [  340,   373,   645,  1049],
        [ 5975,   284,   502,   284],
        [ 3285,   326,    11,   287]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Note that we increase the stride to 4. This is to utilize the data set fully (we don't skip a
single word) but also avoid any overlap between the batches, since more overlap could lead
to increased overfitting.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="CREATING-TOKEN-EMBEDDINGS">CREATING TOKEN EMBEDDINGS<a class="anchor-link" href="#CREATING-TOKEN-EMBEDDINGS">¶</a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Let's illustrate how the token ID to embedding vector conversion works with a hands-on
example. Suppose we have the following four input tokens with IDs 2, 3, 5, and 1:</p></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [41]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>For the sake of simplicity and illustration purposes, suppose we have a small vocabulary of
only 6 words (instead of the 50,257 words in the BPE tokenizer vocabulary), and we want
to create embeddings of size 3 (in GPT-3, the embedding size is 12,288 dimensions):</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Using the vocab_size and output_dim, we can instantiate an embedding layer in PyTorch,
setting the random seed to 123 for reproducibility purposes:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [42]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">embedding_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>The print statement in the code prints the embedding layer's underlying
weight matrix:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [43]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">embedding_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Parameter containing:
tensor([[ 0.3374, -0.1778, -0.1690],
        [ 0.9178,  1.5810,  1.3010],
        [ 1.2753, -0.2010, -0.1606],
        [-0.4015,  0.9666, -1.1481],
        [-1.1589,  0.3255, -0.6315],
        [-2.8400, -0.7849, -1.4096]], requires_grad=True)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>We can see that the weight matrix of the embedding layer contains small, random values.
These values are optimized during LLM training as part of the LLM optimization itself, as we
will see in upcoming chapters. Moreover, we can see that the weight matrix has six rows
and three columns. There is one row for each of the six possible tokens in the vocabulary.
And there is one column for each of the three embedding dimensions.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>After we instantiated the embedding layer, let's now apply it to a token ID to obtain the
embedding vector:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [44]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">embedding_layer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">])))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=&lt;EmbeddingBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>If we compare the embedding vector for token ID 3 to the previous embedding matrix, we
see that it is identical to the 4th row (Python starts with a zero index, so it's the row
corresponding to index 3). In other words, the embedding layer is essentially a look-up
operation that retrieves rows from the embedding layer's weight matrix via a token ID.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Previously, we have seen how to convert a single token ID into a three-dimensional
embedding vector. Let's now apply that to all four input IDs we defined earlier
(torch.tensor([2, 3, 5, 1])):</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [45]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">embedding_layer</span><span class="p">(</span><span class="n">input_ids</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[ 1.2753, -0.2010, -0.1606],
        [-0.4015,  0.9666, -1.1481],
        [-2.8400, -0.7849, -1.4096],
        [ 0.9178,  1.5810,  1.3010]], grad_fn=&lt;EmbeddingBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Each row in this output matrix is obtained via a lookup operation from the embedding
weight matrix</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="POSITIONAL-EMBEDDINGS-(ENCODING-WORD-POSITIONS)">POSITIONAL EMBEDDINGS (ENCODING WORD POSITIONS)<a class="anchor-link" href="#POSITIONAL-EMBEDDINGS-(ENCODING-WORD-POSITIONS)">¶</a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Consider more realistic and useful embedding sizes and encode the input
tokens into a 256-dimensional vector representation.</p>
<p>This is smaller than what the original
GPT-3 model used (in GPT-3, the embedding size is 12,288 dimensions) but still reasonable
for experimentation.</p>
<p>Furthermore, we assume that the token IDs were created by the BPE
tokenizer that we implemented earlier, which has a vocabulary size of 50,257:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [48]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">50257</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">256</span>

<span class="n">token_embedding_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Using the token_embedding_layer above, if we sample data from the data loader, we
embed each token in each batch into a 256-dimensional vector. If we have a batch size of 8
with four tokens each, the result will be an 8 x 4 x 256 tensor.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Let's instantiate the data loader ( Data sampling with a sliding window),
first:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [49]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">max_length</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">create_dataloader_v1</span><span class="p">(</span>
    <span class="n">raw_text</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
    <span class="n">stride</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">data_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
<span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data_iter</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [50]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"Token IDs:</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Inputs shape:</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Token IDs:
 tensor([[   40,   367,  2885,  1464],
        [ 1807,  3619,   402,   271],
        [10899,  2138,   257,  7026],
        [15632,   438,  2016,   257],
        [  922,  5891,  1576,   438],
        [  568,   340,   373,   645],
        [ 1049,  5975,   284,   502],
        [  284,  3285,   326,    11]])

Inputs shape:
 torch.Size([8, 4])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can see, the token ID tensor is 8x4-dimensional, meaning that the data batch
consists of 8 text samples with 4 tokens each.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Let's now use the embedding layer to embed these token IDs into 256-dimensional
vectors:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [51]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">token_embeddings</span> <span class="o">=</span> <span class="n">token_embedding_layer</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">token_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([8, 4, 256])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can tell based on the 8x4x256-dimensional tensor output, each token ID is now
embedded as a 256-dimensional vector.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>For a GPT model's absolute embedding approach, we just need to create another
embedding layer that has the same dimension as the token_embedding_layer:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [52]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">context_length</span> <span class="o">=</span> <span class="n">max_length</span>
<span class="n">pos_embedding_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">context_length</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [53]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">pos_embeddings</span> <span class="o">=</span> <span class="n">pos_embedding_layer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_length</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pos_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([4, 256])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As shown in the preceding code example, the input to the pos_embeddings is usually a
placeholder vector torch.arange(context_length), which contains a sequence of
numbers 0, 1, ..., up to the maximum input length − 1.</p>
<p>The context_length is a variable
that represents the supported input size of the LLM.</p>
<p>Here, we choose it similar to the
maximum length of the input text.</p>
<p>In practice, input text can be longer than the supported
context length, in which case we have to truncate the text.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can see, the positional embedding tensor consists of four 256-dimensional vectors.
We can now add these directly to the token embeddings, where PyTorch will add the 4x256-
dimensional pos_embeddings tensor to each 4x256-dimensional token embedding tensor in
each of the 8 batches:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [54]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">input_embeddings</span> <span class="o">=</span> <span class="n">token_embeddings</span> <span class="o">+</span> <span class="n">pos_embeddings</span>
<span class="nb">print</span><span class="p">(</span><span class="n">input_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([8, 4, 256])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The input_embeddings we created are the embedded input
examples that can now be processed by the main LLM modules</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="IMPLEMENTING-A-SIMPLIFIED-ATTENTION-MECHANISM">IMPLEMENTING A SIMPLIFIED ATTENTION MECHANISM<a class="anchor-link" href="#IMPLEMENTING-A-SIMPLIFIED-ATTENTION-MECHANISM">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Consider the following input sentence, which has already been embedded into 3-
dimensional vectors.</p>
<p>We choose a small embedding dimension for
illustration purposes to ensure it fits on the page without line breaks:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [55]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
  <span class="p">[[</span><span class="mf">0.43</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">],</span> <span class="c1"># Your     (x^1)</span>
   <span class="p">[</span><span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.87</span><span class="p">,</span> <span class="mf">0.66</span><span class="p">],</span> <span class="c1"># journey  (x^2)</span>
   <span class="p">[</span><span class="mf">0.57</span><span class="p">,</span> <span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.64</span><span class="p">],</span> <span class="c1"># starts   (x^3)</span>
   <span class="p">[</span><span class="mf">0.22</span><span class="p">,</span> <span class="mf">0.58</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">],</span> <span class="c1"># with     (x^4)</span>
   <span class="p">[</span><span class="mf">0.77</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">],</span> <span class="c1"># one      (x^5)</span>
   <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">]]</span> <span class="c1"># step     (x^6)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [64]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Generate random 3D coordinates</span>
<span class="n">x_coords</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">y_coords</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">z_coords</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"your"</span><span class="p">,</span> <span class="s2">"journey"</span><span class="p">,</span> <span class="s2">"starts"</span><span class="p">,</span> <span class="s2">"with"</span><span class="p">,</span> <span class="s2">"one"</span><span class="p">,</span> <span class="s2">"step"</span><span class="p">]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'r'</span><span class="p">,</span> <span class="s1">'g'</span><span class="p">,</span> <span class="s1">'b'</span><span class="p">,</span> <span class="s1">'c'</span><span class="p">,</span> <span class="s1">'m'</span><span class="p">,</span> <span class="s1">'y'</span><span class="p">]</span>

<span class="c1"># Create 3D plot</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">'3d'</span><span class="p">)</span>

<span class="c1"># Plot each vector with a different color and annotate</span>
<span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">color</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x_coords</span><span class="p">,</span> <span class="n">y_coords</span><span class="p">,</span> <span class="n">z_coords</span><span class="p">,</span> <span class="n">words</span><span class="p">,</span> <span class="n">colors</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">arrow_length_ratio</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>

<span class="c1"># Set labels</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'X'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Y'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s1">'Z'</span><span class="p">)</span>

<span class="c1"># Set plot limits</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_zlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'3D Plot of Word Embeddings with Colored Vectors'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Each row represents a word, and each column represents an embedding dimension</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>The second input token serves as the query</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [67]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">query</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># 2nd input token is the query</span>

<span class="n">attn_scores_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
    <span class="n">attn_scores_2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x_i</span><span class="p">,</span> <span class="n">query</span><span class="p">)</span> <span class="c1"># dot product (transpose not necessary here since they are 1-dim vectors)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">attn_scores_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>In the next step, we normalize each of the attention scores that
we computed previously.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>The main goal behind the normalization  is to obtain attention weights
that sum up to 1.</p>
<p>This normalization is a convention that is useful for interpretation and for
maintaining training stability in an LLM.</p>
<p>Here's a straightforward method for achieving this
normalization step:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [68]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">attn_weights_2_tmp</span> <span class="o">=</span> <span class="n">attn_scores_2</span> <span class="o">/</span> <span class="n">attn_scores_2</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Attention weights:"</span><span class="p">,</span> <span class="n">attn_weights_2_tmp</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Sum:"</span><span class="p">,</span> <span class="n">attn_weights_2_tmp</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])
Sum: tensor(1.0000)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>In practice, it's more common and advisable to use the softmax function for normalization.</p>
<p>This approach is better at managing extreme values and offers more favorable gradient
properties during training.</p>
<p>Below is a basic implementation of the softmax function for
normalizing the attention scores:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [69]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">softmax_naive</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">attn_weights_2_naive</span> <span class="o">=</span> <span class="n">softmax_naive</span><span class="p">(</span><span class="n">attn_scores_2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Attention weights:"</span><span class="p">,</span> <span class="n">attn_weights_2_naive</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Sum:"</span><span class="p">,</span> <span class="n">attn_weights_2_naive</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])
Sum: tensor(1.)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As the output shows, the softmax function also meets the objective and normalizes the
attention weights such that they sum to 1:</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>In addition, the softmax function ensures that the attention weights are always positive.
This makes the output interpretable as probabilities or relative importance, where higher
weights indicate greater importance.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Note that this naive softmax implementation (softmax_naive) may encounter numerical
instability problems, such as overflow and underflow, when dealing with large or small input
values.</p>
<p>Therefore, in practice, it's advisable to use the PyTorch implementation of softmax,
which has been extensively optimized for performance:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [70]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">attn_weights_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn_scores_2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Attention weights:"</span><span class="p">,</span> <span class="n">attn_weights_2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Sum:"</span><span class="p">,</span> <span class="n">attn_weights_2</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])
Sum: tensor(1.)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>In this case, we can see that it yields the same results as our previous softmax_naive
function:</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>The context vector z(2)is calculated as a weighted sum of all input
vectors.</p>
<p>This involves multiplying each input vector by its corresponding attention weight:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [71]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">query</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># 2nd input token is the query</span>

<span class="n">context_vec_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">query</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">x_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
    <span class="n">context_vec_2</span> <span class="o">+=</span> <span class="n">attn_weights_2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">x_i</span>

<span class="nb">print</span><span class="p">(</span><span class="n">context_vec_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0.4419, 0.6515, 0.5683])
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [72]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>

<span class="n">inputs2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
  <span class="p">[[</span><span class="mf">0.43</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">],</span> <span class="c1"># Your     (x^1)</span>
   <span class="p">[</span><span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.87</span><span class="p">,</span> <span class="mf">0.66</span><span class="p">],</span> <span class="c1"># journey  (x^2)</span>
   <span class="p">[</span><span class="mf">0.57</span><span class="p">,</span> <span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.64</span><span class="p">],</span> <span class="c1"># starts   (x^3)</span>
   <span class="p">[</span><span class="mf">0.22</span><span class="p">,</span> <span class="mf">0.58</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">],</span> <span class="c1"># with     (x^4)</span>
   <span class="p">[</span><span class="mf">0.77</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">],</span> <span class="c1"># one      (x^5)</span>
   <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">],</span> <span class="c1"># step     (x^6)</span>
   <span class="p">[</span><span class="mf">0.4419</span><span class="p">,</span> <span class="mf">0.6515</span><span class="p">,</span> <span class="mf">0.5683</span><span class="p">]]</span>
<span class="p">)</span>

<span class="c1"># Corresponding words</span>
<span class="n">words2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Your'</span><span class="p">,</span> <span class="s1">'journey'</span><span class="p">,</span> <span class="s1">'starts'</span><span class="p">,</span> <span class="s1">'with'</span><span class="p">,</span> <span class="s1">'one'</span><span class="p">,</span> <span class="s1">'step'</span><span class="p">,</span> <span class="s1">'journey-context'</span><span class="p">]</span>

<span class="c1"># Extract x, y, z coordinates</span>
<span class="n">x_coords</span> <span class="o">=</span> <span class="n">inputs2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">y_coords</span> <span class="o">=</span> <span class="n">inputs2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">z_coords</span> <span class="o">=</span> <span class="n">inputs2</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="c1"># Create 3D plot</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">'3d'</span><span class="p">)</span>

<span class="c1"># Plot each point and annotate with corresponding word</span>
<span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x_coords</span><span class="p">,</span> <span class="n">y_coords</span><span class="p">,</span> <span class="n">z_coords</span><span class="p">,</span> <span class="n">words2</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Set labels for axes</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'X'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Y'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s1">'Z'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'3D Plot of Word Embeddings'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Create 3D plot with vectors from origin to each point, using different colors</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">'3d'</span><span class="p">)</span>

<span class="c1"># Define a list of colors for the vectors</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'r'</span><span class="p">,</span> <span class="s1">'g'</span><span class="p">,</span> <span class="s1">'b'</span><span class="p">,</span> <span class="s1">'c'</span><span class="p">,</span> <span class="s1">'m'</span><span class="p">,</span> <span class="s1">'y'</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">]</span>

<span class="c1"># Plot each vector with a different color and annotate with the corresponding word</span>
<span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">color</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x_coords</span><span class="p">,</span> <span class="n">y_coords</span><span class="p">,</span> <span class="n">z_coords</span><span class="p">,</span> <span class="n">words2</span><span class="p">,</span> <span class="n">colors</span><span class="p">):</span>
    <span class="c1"># Draw vector from origin to the point (x, y, z) with specified color and smaller arrow length ratio</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">arrow_length_ratio</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>

<span class="c1"># Set labels for axes</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'X'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Y'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s1">'Z'</span><span class="p">)</span>

<span class="c1"># Set plot limits to keep arrows within the plot boundaries</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_zlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'3D Plot of Word Embeddings with Colored Vectors'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Now, we can extend this computation to
calculate attention weights and context vectors for all inputs.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>First, we add an additional for-loop to compute the
dot products for all pairs of inputs.</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [73]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">attn_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">x_j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
        <span class="n">attn_scores</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x_i</span><span class="p">,</span> <span class="n">x_j</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">attn_scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],
        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],
        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],
        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],
        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],
        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Each element in the preceding tensor represents an attention score between each pair of
inputs.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>When computing the preceding attention score tensor, we used for-loops in Python.</p>
<p>However, for-loops are generally slow, and we can achieve the same results using matrix
multiplication:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [74]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">attn_scores</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">@</span> <span class="n">inputs</span><span class="o">.</span><span class="n">T</span>
<span class="nb">print</span><span class="p">(</span><span class="n">attn_scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],
        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],
        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],
        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],
        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],
        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>We now normalize each row so that the values in
each row sum to 1:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [75]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn_scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],
        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],
        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],
        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],
        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],
        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>In the context of using PyTorch, the dim parameter in functions like torch.softmax specifies
the dimension of the input tensor along which the function will be computed.</p>
<p>By setting
dim=-1, we are instructing the softmax function to apply the normalization along the last
dimension of the attn_scores tensor.</p>
<p>If attn_scores is a 2D tensor (for example, with a
shape of [rows, columns]), dim=-1 will normalize across the columns so that the values in
each row (summing over the column dimension) sum up to 1.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Let's briefly verify that
the rows indeed all sum to 1:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [76]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">row_2_sum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="mf">0.1385</span><span class="p">,</span> <span class="mf">0.2379</span><span class="p">,</span> <span class="mf">0.2333</span><span class="p">,</span> <span class="mf">0.1240</span><span class="p">,</span> <span class="mf">0.1082</span><span class="p">,</span> <span class="mf">0.1581</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Row 2 sum:"</span><span class="p">,</span> <span class="n">row_2_sum</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"All row sums:"</span><span class="p">,</span> <span class="n">attn_weights</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Row 2 sum: 1.0
All row sums: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>In the third and last step, we now use these attention weights to compute all context
vectors via matrix multiplication:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [77]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">all_context_vecs</span> <span class="o">=</span> <span class="n">attn_weights</span> <span class="o">@</span> <span class="n">inputs</span>
<span class="nb">print</span><span class="p">(</span><span class="n">all_context_vecs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0.4421, 0.5931, 0.5790],
        [0.4419, 0.6515, 0.5683],
        [0.4431, 0.6496, 0.5671],
        [0.4304, 0.6298, 0.5510],
        [0.4671, 0.5910, 0.5266],
        [0.4177, 0.6503, 0.5645]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>We can double-check that the code is correct by comparing the 2nd row with the context
vector z(2) calculated previously</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [78]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"Previous 2nd context vector:"</span><span class="p">,</span> <span class="n">context_vec_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Previous 2nd context vector: tensor([0.4419, 0.6515, 0.5683])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Based on the result, we can see that the previously calculated context_vec_2 matches the
second row in the previous tensor exactly</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>This concludes the code walkthrough of a simple self-attention mechanism.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="IMPLEMENTING-SELF-ATTENTION-WITH-TRAINABLE-WEIGHTS">IMPLEMENTING SELF ATTENTION WITH TRAINABLE WEIGHTS<a class="anchor-link" href="#IMPLEMENTING-SELF-ATTENTION-WITH-TRAINABLE-WEIGHTS">¶</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [79]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
  <span class="p">[[</span><span class="mf">0.43</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">],</span> <span class="c1"># Your     (x^1)</span>
   <span class="p">[</span><span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.87</span><span class="p">,</span> <span class="mf">0.66</span><span class="p">],</span> <span class="c1"># journey  (x^2)</span>
   <span class="p">[</span><span class="mf">0.57</span><span class="p">,</span> <span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.64</span><span class="p">],</span> <span class="c1"># starts   (x^3)</span>
   <span class="p">[</span><span class="mf">0.22</span><span class="p">,</span> <span class="mf">0.58</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">],</span> <span class="c1"># with     (x^4)</span>
   <span class="p">[</span><span class="mf">0.77</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">],</span> <span class="c1"># one      (x^5)</span>
   <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">]]</span> <span class="c1"># step     (x^6)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Let's begin by defining a few variables:</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<h1 id="A-The-second-input-element">A The second input element<a class="anchor-link" href="#A-The-second-input-element">¶</a></h1><h1 id="B-The-input-embedding-size,-d=3">B The input embedding size, d=3<a class="anchor-link" href="#B-The-input-embedding-size,-d=3">¶</a></h1><h1 id="C-The-output-embedding-size,-d_out=2">C The output embedding size, d_out=2<a class="anchor-link" href="#C-The-output-embedding-size,-d_out=2">¶</a></h1></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [80]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">x_2</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1">#A</span>
<span class="n">d_in</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1">#B</span>
<span class="n">d_out</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1">#C</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Note that in GPT-like models, the input and output dimensions are usually the same.</p>
<p>But for illustration purposes, to better follow the computation, we choose different input (d_in=3)
and output (d_out=2) dimensions here.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Next, we initialize the three weight matrices Wq, Wk and Wv</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [81]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">W_query</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">W_key</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">W_value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [82]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">W_query</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Parameter containing:
tensor([[0.2961, 0.5166],
        [0.2517, 0.6886],
        [0.0740, 0.8665]])
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [83]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">W_key</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Parameter containing:
tensor([[0.1366, 0.1025],
        [0.1841, 0.7264],
        [0.3153, 0.6871]])
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [84]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">W_value</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Parameter containing:
tensor([[0.0756, 0.1966],
        [0.3164, 0.4017],
        [0.1186, 0.8274]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Note that we are setting requires_grad=False to reduce clutter in the outputs for
illustration purposes.</p>
<p>If we were to use the weight matrices for model training, we
would set requires_grad=True to update these matrices during model training.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Next, we compute the query, key, and value vectors as shown earlier</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [85]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">query_2</span> <span class="o">=</span> <span class="n">x_2</span> <span class="o">@</span> <span class="n">W_query</span>
<span class="n">key_2</span> <span class="o">=</span> <span class="n">x_2</span> <span class="o">@</span> <span class="n">W_key</span>
<span class="n">value_2</span> <span class="o">=</span> <span class="n">x_2</span> <span class="o">@</span> <span class="n">W_value</span>
<span class="nb">print</span><span class="p">(</span><span class="n">query_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0.4306, 1.4551])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can see based on the output for the query, this results in a 2-dimensional vector.</p>
<p>This is because: we set the number of columns of the corresponding weight matrix, via d_out, to 2:</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Even though our temporary goal is to only compute the one context vector z(2),  we still
require the key and value vectors for all input elements.</p>
<p>This is because they are involved in computing the attention weights with respect to the query q(2)</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>We can obtain all keys and values via matrix multiplication:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [86]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">keys</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">@</span> <span class="n">W_key</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">@</span> <span class="n">W_value</span>
<span class="n">queries</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">@</span> <span class="n">W_query</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"keys.shape:"</span><span class="p">,</span> <span class="n">keys</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"values.shape:"</span><span class="p">,</span> <span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"queries.shape:"</span><span class="p">,</span> <span class="n">queries</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>keys.shape: torch.Size([6, 2])
values.shape: torch.Size([6, 2])
queries.shape: torch.Size([6, 2])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can tell from the outputs, we successfully projected the 6 input tokens from a 3D
onto a 2D embedding space:</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>First, let's compute the attention score ω22</p></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [87]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">keys_2</span> <span class="o">=</span> <span class="n">keys</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1">#A</span>
<span class="n">attn_score_22</span> <span class="o">=</span> <span class="n">query_2</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">keys_2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">attn_score_22</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor(1.8524)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
Again, we can generalize this computation to all attention scores via matrix multiplication:</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [88]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">attn_scores_2</span> <span class="o">=</span> <span class="n">query_2</span> <span class="o">@</span> <span class="n">keys</span><span class="o">.</span><span class="n">T</span> <span class="c1"># All attention scores for given query</span>
<span class="nb">print</span><span class="p">(</span><span class="n">attn_scores_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [89]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">attn_scores</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">@</span> <span class="n">keys</span><span class="o">.</span><span class="n">T</span> 
<span class="c1"># omega</span>
<span class="nb">print</span><span class="p">(</span><span class="n">attn_scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0.9231, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],
        [1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],
        [1.2544, 1.8284, 1.7877, 1.0654, 0.5508, 1.5238],
        [0.6973, 1.0167, 0.9941, 0.5925, 0.3061, 0.8475],
        [0.6114, 0.8819, 0.8626, 0.5121, 0.2707, 0.7307],
        [0.8995, 1.3165, 1.2871, 0.7682, 0.3937, 1.0996]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>We compute the attention weights by scaling the
attention scores and using the softmax function we used earlier.</p>
<p>The difference to earlier is
that we now scale the attention scores by dividing them by the square root of the
embedding dimension of the keys.</p>
<p>Note that taking the square root is mathematically the
same as exponentiating by 0.5:</p></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [90]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">d_k</span> <span class="o">=</span> <span class="n">keys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">attn_weights_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn_scores_2</span> <span class="o">/</span> <span class="n">d_k</span><span class="o">**</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">attn_weights_2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">d_k</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])
2
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="DIVIDE-BY-SQRT-(DIMENSION)">DIVIDE BY SQRT (DIMENSION)<a class="anchor-link" href="#DIVIDE-BY-SQRT-(DIMENSION)">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Reason 1: For stability in learning</p>
<p>The softmax function is sensitive to the magnitudes of its inputs. When the inputs are large, the differences between the exponential values of each input become much more pronounced. This causes the softmax output to become "peaky," where the highest value receives almost all the probability mass, and the rest receive very little.</p>
<p>In attention mechanisms, particularly in transformers, if the dot products between query and key vectors become too large (like multiplying by 8 in this example), the attention scores can become very large. This results in a very sharp softmax distribution, making the model overly confident in one particular "key." Such sharp distributions can make learning unstable,</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [91]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># Define the tensor</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>

<span class="c1"># Apply softmax without scaling</span>
<span class="n">softmax_result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Softmax without scaling:"</span><span class="p">,</span> <span class="n">softmax_result</span><span class="p">)</span>

<span class="c1"># Multiply the tensor by 8 and then apply softmax</span>
<span class="n">scaled_tensor</span> <span class="o">=</span> <span class="n">tensor</span> <span class="o">*</span> <span class="mi">8</span>
<span class="n">softmax_scaled_result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaled_tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Softmax after scaling (tensor * 8):"</span><span class="p">,</span> <span class="n">softmax_scaled_result</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Softmax without scaling: tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])
Softmax after scaling (tensor * 8): tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="BUT-WHY-SQRT?">BUT WHY SQRT?<a class="anchor-link" href="#BUT-WHY-SQRT?">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Reason 2: To make the variance of the dot product stable</p>
<p>The dot product of  Q and K increases the variance because multiplying two random numbers increases the variance.</p>
<p>The increase in variance grows with the dimension.</p>
<p>Dividing by sqrt (dimension) keeps the variance close to 1</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [92]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Function to compute variance before and after scaling</span>
<span class="k">def</span> <span class="nf">compute_variance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">num_trials</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">dot_products</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">scaled_dot_products</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Generate multiple random vectors and compute dot products</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_trials</span><span class="p">):</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>

        <span class="c1"># Compute dot product</span>
        <span class="n">dot_product</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
        <span class="n">dot_products</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dot_product</span><span class="p">)</span>

        <span class="c1"># Scale the dot product by sqrt(dim)</span>
        <span class="n">scaled_dot_product</span> <span class="o">=</span> <span class="n">dot_product</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="n">scaled_dot_products</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scaled_dot_product</span><span class="p">)</span>

    <span class="c1"># Calculate variance of the dot products</span>
    <span class="n">variance_before_scaling</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dot_products</span><span class="p">)</span>
    <span class="n">variance_after_scaling</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">scaled_dot_products</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">variance_before_scaling</span><span class="p">,</span> <span class="n">variance_after_scaling</span>

<span class="c1"># For dimension 5</span>
<span class="n">variance_before_5</span><span class="p">,</span> <span class="n">variance_after_5</span> <span class="o">=</span> <span class="n">compute_variance</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Variance before scaling (dim=5): </span><span class="si">{</span><span class="n">variance_before_5</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Variance after scaling (dim=5): </span><span class="si">{</span><span class="n">variance_after_5</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># For dimension 20</span>
<span class="n">variance_before_100</span><span class="p">,</span> <span class="n">variance_after_100</span> <span class="o">=</span> <span class="n">compute_variance</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Variance before scaling (dim=100): </span><span class="si">{</span><span class="n">variance_before_100</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Variance after scaling (dim=100): </span><span class="si">{</span><span class="n">variance_after_100</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Variance before scaling (dim=5): 5.161519978408116
Variance after scaling (dim=5): 1.0323039956816233
Variance before scaling (dim=100): 94.46831703771485
Variance after scaling (dim=100): 0.9446831703771486
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>We now compute the context vector as a weighted sum over the value
vectors.</p>
<p>Here, the attention weights serve as a weighting factor that weighs the respective
importance of each value vector.</p>
<p>We can use matrix multiplication to
obtain the output in one step:</p></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [93]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">context_vec_2</span> <span class="o">=</span> <span class="n">attn_weights_2</span> <span class="o">@</span> <span class="n">values</span>
<span class="nb">print</span><span class="p">(</span><span class="n">context_vec_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([0.3061, 0.8210])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>So far, we only computed a single context vector, z(2).</p>
<p>In the next section, we will generalize the code to compute all context vectors in the input sequence, z(1)to z (T)</p></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="IMPLEMENTING-A-COMPACT-SELF-ATTENTION-PYTHON-CLASS">IMPLEMENTING A COMPACT SELF ATTENTION PYTHON CLASS<a class="anchor-link" href="#IMPLEMENTING-A-COMPACT-SELF-ATTENTION-PYTHON-CLASS">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>In the previous sections, we have gone through a lot of steps to compute the self-attention
outputs.</p>
<p>This was mainly done for illustration purposes so we could go through one step at
a time.</p>
<p>In practice, with the LLM implementation in the next chapter in mind, it is helpful to
organize this code into a Python class as follows:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [94]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">SelfAttention_v1</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_query</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_key</span>   <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_key</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_query</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_value</span>

        <span class="n">attn_scores</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">@</span> <span class="n">keys</span><span class="o">.</span><span class="n">T</span> <span class="c1"># omega</span>
        <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span>
            <span class="n">attn_scores</span> <span class="o">/</span> <span class="n">keys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>

        <span class="n">context_vec</span> <span class="o">=</span> <span class="n">attn_weights</span> <span class="o">@</span> <span class="n">values</span>
        <span class="k">return</span> <span class="n">context_vec</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>In this PyTorch code, SelfAttention_v1 is a class derived from nn.Module, which is a
fundamental building block of PyTorch models, which provides necessary functionalities for
model layer creation and management.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The <strong>init</strong> method initializes trainable weight matrices (W_query, W_key, and
W_value) for queries, keys, and values, each transforming the input dimension d_in to an
output dimension d_out.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>During the forward pass, using the forward method, we compute the attention scores
(attn_scores) by multiplying queries and keys, normalizing these scores using softmax.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Finally, we create a context vector by weighting the values with these normalized attention
scores.</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [95]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">sa_v1</span> <span class="o">=</span> <span class="n">SelfAttention_v1</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sa_v1</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0.2996, 0.8053],
        [0.3061, 0.8210],
        [0.3058, 0.8203],
        [0.2948, 0.7939],
        [0.2927, 0.7891],
        [0.2990, 0.8040]], grad_fn=&lt;MmBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Since inputs contains six embedding vectors, we get a matrix storing the six
context vectors, as shown in the above result.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As a quick check, notice how the second row ([0.3061, 0.8210]) matches the contents of
context_vec_2 in the previous section.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>We can improve the SelfAttention_v1 implementation further by utilizing PyTorch's
nn.Linear layers, which effectively perform matrix multiplication when the bias units are
disabled.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Additionally, a significant advantage of using nn.Linear instead of manually
implementing nn.Parameter(torch.rand(...)) is that nn.Linear has an optimized weight
initialization scheme, contributing to more stable and effective model training.</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [96]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">SelfAttention_v2</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">qkv_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_query</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_key</span>   <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_key</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_query</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">attn_scores</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">@</span> <span class="n">keys</span><span class="o">.</span><span class="n">T</span>
        <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn_scores</span> <span class="o">/</span> <span class="n">keys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">context_vec</span> <span class="o">=</span> <span class="n">attn_weights</span> <span class="o">@</span> <span class="n">values</span>
        <span class="k">return</span> <span class="n">context_vec</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>You can use the SelfAttention_v2 similar to SelfAttention_v1:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [97]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">789</span><span class="p">)</span>
<span class="n">sa_v2</span> <span class="o">=</span> <span class="n">SelfAttention_v2</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sa_v2</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[-0.0739,  0.0713],
        [-0.0748,  0.0703],
        [-0.0749,  0.0702],
        [-0.0760,  0.0685],
        [-0.0763,  0.0679],
        [-0.0754,  0.0693]], grad_fn=&lt;MmBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Note that SelfAttention_v1 and SelfAttention_v2 give different outputs because they
use different initial weights for the weight matrices since nn.Linear uses a more
sophisticated weight initialization scheme.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="HIDING-FUTURE-WORDS-WITH-CAUSAL-ATTENTION">HIDING FUTURE WORDS WITH CAUSAL ATTENTION<a class="anchor-link" href="#HIDING-FUTURE-WORDS-WITH-CAUSAL-ATTENTION">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Let's work with the attention scores and weights from the previous section to code the causal attention mechanism.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>In the first step illustrated in Figure 3.20, we compute the attention weights using the
softmax function as we have done in previous sections:</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Reuse the query and key weight matrices of the SelfAttention_v2 object from the previous section for
convenience</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [98]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
  <span class="p">[[</span><span class="mf">0.43</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">],</span> <span class="c1"># Your     (x^1)</span>
   <span class="p">[</span><span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.87</span><span class="p">,</span> <span class="mf">0.66</span><span class="p">],</span> <span class="c1"># journey  (x^2)</span>
   <span class="p">[</span><span class="mf">0.57</span><span class="p">,</span> <span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.64</span><span class="p">],</span> <span class="c1"># starts   (x^3)</span>
   <span class="p">[</span><span class="mf">0.22</span><span class="p">,</span> <span class="mf">0.58</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">],</span> <span class="c1"># with     (x^4)</span>
   <span class="p">[</span><span class="mf">0.77</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">],</span> <span class="c1"># one      (x^5)</span>
   <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">]]</span> <span class="c1"># step     (x^6)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [99]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">queries</span> <span class="o">=</span> <span class="n">sa_v2</span><span class="o">.</span><span class="n">W_query</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="c1">#A</span>
<span class="n">keys</span> <span class="o">=</span> <span class="n">sa_v2</span><span class="o">.</span><span class="n">W_key</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">attn_scores</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">@</span> <span class="n">keys</span><span class="o">.</span><span class="n">T</span>
<span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn_scores</span> <span class="o">/</span> <span class="n">keys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],
        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],
        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],
        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],
        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],
        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],
       grad_fn=&lt;SoftmaxBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>We can now use PyTorch's tril function to create a mask
where the values above the diagonal are zero:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [100]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">context_length</span><span class="p">,</span> <span class="n">context_length</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[100]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [101]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">context_length</span> <span class="o">=</span> <span class="n">attn_scores</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">mask_simple</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">context_length</span><span class="p">,</span> <span class="n">context_length</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mask_simple</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[1., 0., 0., 0., 0., 0.],
        [1., 1., 0., 0., 0., 0.],
        [1., 1., 1., 0., 0., 0.],
        [1., 1., 1., 1., 0., 0.],
        [1., 1., 1., 1., 1., 0.],
        [1., 1., 1., 1., 1., 1.]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Now, we can multiply this mask with the attention weights to zero out the values above the
diagonal:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [102]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">masked_simple</span> <span class="o">=</span> <span class="n">attn_weights</span><span class="o">*</span><span class="n">mask_simple</span>
<span class="nb">print</span><span class="p">(</span><span class="n">masked_simple</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],
        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],
        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],
        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],
       grad_fn=&lt;MulBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can see, the elements above the diagonal are successfully zeroed out</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>The third step is to renormalize the attention weights to sum up to 1 again in
each row.</p>
<p>We can achieve this by dividing each element in each row by the sum in each
row:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [103]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">row_sums</span> <span class="o">=</span> <span class="n">masked_simple</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">masked_simple_norm</span> <span class="o">=</span> <span class="n">masked_simple</span> <span class="o">/</span> <span class="n">row_sums</span>
<span class="nb">print</span><span class="p">(</span><span class="n">masked_simple_norm</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],
        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],
        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],
        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],
       grad_fn=&lt;DivBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>The result is an attention weight matrix where the attention weights above the diagonal are
zeroed out and where the rows sum to 1.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>While we could be technically done with implementing causal attention at this point, we can
take advantage of a mathematical property of the softmax function.</p>
<p>We can implement the computation of the masked attention weights more efficiently in fewer steps.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>The softmax function converts its inputs into a probability distribution.</p>
<p>When negative
infinity values (-∞) are present in a row, the softmax function treats them as zero
probability.</p>
<p>(Mathematically, this is because e
-∞ approaches 0.)</p>
<p>We can implement this more efficient masking "trick" by creating a mask with 1's above
the diagonal and then replacing these 1's with negative infinity (-inf) values:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [104]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">attn_scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[ 0.2899,  0.0716,  0.0760, -0.0138,  0.1344, -0.0511],
        [ 0.4656,  0.1723,  0.1751,  0.0259,  0.1771,  0.0085],
        [ 0.4594,  0.1703,  0.1731,  0.0259,  0.1745,  0.0090],
        [ 0.2642,  0.1024,  0.1036,  0.0186,  0.0973,  0.0122],
        [ 0.2183,  0.0874,  0.0882,  0.0177,  0.0786,  0.0144],
        [ 0.3408,  0.1270,  0.1290,  0.0198,  0.1290,  0.0078]],
       grad_fn=&lt;MmBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [105]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">context_length</span><span class="p">,</span> <span class="n">context_length</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[105]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[1., 1., 1., 1., 1., 1.],
        [0., 1., 1., 1., 1., 1.],
        [0., 0., 1., 1., 1., 1.],
        [0., 0., 0., 1., 1., 1.],
        [0., 0., 0., 0., 1., 1.],
        [0., 0., 0., 0., 0., 1.]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [106]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">context_length</span><span class="p">,</span> <span class="n">context_length</span><span class="p">),</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0., 1., 1., 1., 1., 1.],
        [0., 0., 1., 1., 1., 1.],
        [0., 0., 0., 1., 1., 1.],
        [0., 0., 0., 0., 1., 1.],
        [0., 0., 0., 0., 0., 1.],
        [0., 0., 0., 0., 0., 0.]])
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [107]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">context_length</span><span class="p">,</span> <span class="n">context_length</span><span class="p">),</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">masked</span> <span class="o">=</span> <span class="n">attn_scores</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">bool</span><span class="p">(),</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">masked</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],
        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],
        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],
        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],
        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],
        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],
       grad_fn=&lt;MaskedFillBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Now, all we need to do is apply the softmax function to these masked results, and we are
done.</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [108]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">masked</span> <span class="o">/</span> <span class="n">keys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],
        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],
        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],
        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],
       grad_fn=&lt;SoftmaxBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can see based on the output, the values in each row sum to 1, and no further
normalization is necessary.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Masking in Transformers sets scores for future tokens to a large negative value, making their influence in the softmax calculation effectively zero.</p>
<p>The softmax function then recalculates attention weights only among the unmasked tokens.</p>
<p>This process ensures no information leakage from masked tokens, focusing the model solely on the intended data.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>We could now use the modified attention weights to compute the context vectors via
context_vec = attn_weights @ values.</p>
<p>However, in the next section,
we first cover another minor tweak to the causal attention mechanism that is useful for
reducing overfitting when training LLMs.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="MASKING-ADDITIONAL-ATTENTION-WEIGHTS-WITH-DROPOUT">MASKING ADDITIONAL ATTENTION WEIGHTS WITH DROPOUT<a class="anchor-link" href="#MASKING-ADDITIONAL-ATTENTION-WEIGHTS-WITH-DROPOUT">¶</a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>In the following code example, we use a dropout rate of 50%, which means masking out
half of the attention weights.</p>
<p>When we train the GPT model in later chapters, we will use a
lower dropout rate, such as 0.1 or 0.2.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>In the following code, we apply PyTorch's dropout implementation first to a 6×6 tensor
consisting of ones for illustration purposes:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [109]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">example</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span> <span class="c1">#B</span>
<span class="nb">print</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1.]])
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [110]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span> <span class="c1">#A</span>
<span class="n">example</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span> <span class="c1">#B</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dropout</span><span class="p">(</span><span class="n">example</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[2., 2., 0., 2., 2., 0.],
        [0., 0., 0., 2., 0., 2.],
        [2., 2., 2., 2., 0., 2.],
        [0., 2., 2., 0., 0., 2.],
        [0., 2., 0., 2., 0., 2.],
        [0., 2., 2., 2., 2., 0.]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>When applying dropout to an attention weight matrix with a rate of 50%, half of the
elements in the matrix are randomly set to zero.</p>
<p>To compensate for the reduction in active
elements, the values of the remaining elements in the matrix are scaled up by a factor of
1/0.5 =2.</p>
<p>This scaling is crucial to maintain the overall balance of the attention weights,
ensuring that the average influence of the attention mechanism remains consistent during
both the training and inference phases.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Now, let's apply dropout to the attention weight matrix itself:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [111]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dropout</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.7599, 0.6194, 0.6206, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.4921, 0.4925, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.3966, 0.0000, 0.3775, 0.0000, 0.0000],
        [0.0000, 0.3327, 0.3331, 0.3084, 0.3331, 0.0000]],
       grad_fn=&lt;MulBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can see above, the resulting attention weight matrix now has additional elements zeroed out and the
remaining ones rescaled.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Having gained an understanding of causal attention and dropout masking, we will
develop a concise Python class in the following section.</p>
<p>This class is designed to facilitate
the efficient application of these two techniques.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="IMPLEMENTING-A-COMPACT-CAUSAL-ATTENTION-CLASS">IMPLEMENTING A COMPACT CAUSAL ATTENTION CLASS<a class="anchor-link" href="#IMPLEMENTING-A-COMPACT-CAUSAL-ATTENTION-CLASS">¶</a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>In this section, we will now incorporate the causal attention and dropout modifications into
the SelfAttention Python class we developed in section 3.4.</p>
<p>This class will then serve as a
template for developing multi-head attention in the upcoming section.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Before we begin, one more thing is to ensure that the code can handle batches
consisting of more than one input.</p>
<p>This will ensure that the CausalAttention class supports the batch
outputs produced by the data loader we implemented earlier.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>For simplicity, to simulate such batch inputs, we duplicate the input text example:</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>2 inputs with 6 tokens each, and each token has embedding dimension 3</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [112]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
  <span class="p">[[</span><span class="mf">0.43</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">],</span> <span class="c1"># Your     (x^1)</span>
   <span class="p">[</span><span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.87</span><span class="p">,</span> <span class="mf">0.66</span><span class="p">],</span> <span class="c1"># journey  (x^2)</span>
   <span class="p">[</span><span class="mf">0.57</span><span class="p">,</span> <span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.64</span><span class="p">],</span> <span class="c1"># starts   (x^3)</span>
   <span class="p">[</span><span class="mf">0.22</span><span class="p">,</span> <span class="mf">0.58</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">],</span> <span class="c1"># with     (x^4)</span>
   <span class="p">[</span><span class="mf">0.77</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">],</span> <span class="c1"># one      (x^5)</span>
   <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">]]</span> <span class="c1"># step     (x^6)</span>
<span class="p">)</span>
<span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">inputs</span><span class="p">,</span> <span class="n">inputs</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([2, 6, 3])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>This results in a 3D tensor consisting of 2 input texts with 6 tokens each, where each token
is a 3-dimensional embedding vector.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>The following CausalAttention class is similar to the SelfAttention class we
implemented earlier, except that we now added the dropout and causal mask components
as highlighted in the following code.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Step 1: Compared to the previous SelfAttention_v1 class, we added a dropout layer.</p>
<p>Step 2: The register_buffer call is also a new addition (more information is provided in the following text).</p>
<p>Step 3:  We transpose dimensions 1 and 2, keeping the batch dimension at the first position (0).</p>
<p>Step 4: In PyTorch, operations with a trailing underscore are performed in-place, avoiding unnecessary memory
copies</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [113]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">CausalAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">context_length</span><span class="p">,</span>
                 <span class="n">dropout</span><span class="p">,</span> <span class="n">qkv_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_out</span> <span class="o">=</span> <span class="n">d_out</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_query</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_key</span>   <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span> <span class="c1"># New</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">'mask'</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">context_length</span><span class="p">,</span> <span class="n">context_length</span><span class="p">),</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># New</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">num_tokens</span><span class="p">,</span> <span class="n">d_in</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># New batch dimension b</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_key</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_query</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">attn_scores</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">@</span> <span class="n">keys</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># Changed transpose</span>
        <span class="n">attn_scores</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span>  <span class="c1"># New, _ ops are in-place</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()[:</span><span class="n">num_tokens</span><span class="p">,</span> <span class="p">:</span><span class="n">num_tokens</span><span class="p">],</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>  <span class="c1"># `:num_tokens` to account for cases where the number of tokens in the batch is smaller than the supported context_size</span>
        <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span>
            <span class="n">attn_scores</span> <span class="o">/</span> <span class="n">keys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">attn_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">)</span> <span class="c1"># New</span>

        <span class="n">context_vec</span> <span class="o">=</span> <span class="n">attn_weights</span> <span class="o">@</span> <span class="n">values</span>
        <span class="k">return</span> <span class="n">context_vec</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The use of register_buffer in
PyTorch is not strictly necessary for all use cases but offers several advantages here.</p>
<p>For
instance, when we use the CausalAttention class in our LLM, buffers are automatically
moved to the appropriate device (CPU or GPU) along with our model, which will be relevant
when training the LLM in future chapters.</p>
<p>This means we don't need to manually ensure
these tensors are on the same device as your model parameters, avoiding device mismatch
errors.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>We can use the CausalAttention class as follows, similar to SelfAttention previously:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [116]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">context_length</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ca</span> <span class="o">=</span> <span class="n">CausalAttention</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">context_length</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
<span class="n">context_vecs</span> <span class="o">=</span> <span class="n">ca</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"context_vecs.shape:"</span><span class="p">,</span> <span class="n">context_vecs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>context_vecs.shape: torch.Size([2, 6, 2])
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [117]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">context_vecs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[[-0.4519,  0.2216],
         [-0.5874,  0.0058],
         [-0.6300, -0.0632],
         [-0.5675, -0.0843],
         [-0.5526, -0.0981],
         [-0.5299, -0.1081]],

        [[-0.4519,  0.2216],
         [-0.5874,  0.0058],
         [-0.6300, -0.0632],
         [-0.5675, -0.0843],
         [-0.5526, -0.0981],
         [-0.5299, -0.1081]]], grad_fn=&lt;UnsafeViewBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can see, the resulting context vector is a 3D tensor where each token is now represented by a 2D
embedding:</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>In the next section, we will expand on this concept
and implement a multi-head attention module, that implements several of such causal
attention mechanisms in parallel.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="EXTENDING-SINGLE-HEAD-ATTENTION-TO-MULTI-HEAD-ATTENTION">EXTENDING SINGLE HEAD ATTENTION TO MULTI-HEAD ATTENTION<a class="anchor-link" href="#EXTENDING-SINGLE-HEAD-ATTENTION-TO-MULTI-HEAD-ATTENTION">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
In practical terms, implementing multi-head attention involves creating multiple instances
of the self-attention mechanism, each with
its own weights, and then combining their outputs
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
In code, we can achieve this by implementing a simple MultiHeadAttentionWrapper
class that stacks multiple instances of our previously implemented CausalAttention
module:
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [118]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">MultiHeadAttentionWrapper</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">context_length</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">qkv_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
            <span class="p">[</span><span class="n">CausalAttention</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">context_length</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">qkv_bias</span><span class="p">)</span>
             <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_heads</span><span class="p">)]</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">head</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">heads</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>For example, if we use this MultiHeadAttentionWrapper class with two attention heads (via
num_heads=2) and CausalAttention output dimension d_out=2, this results in a 4-
dimensional context vectors (d_out*num_heads=4)</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
To illustrate further with a concrete example, we can use the
MultiHeadAttentionWrapper class similar to the CausalAttention class before:
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [119]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
  <span class="p">[[</span><span class="mf">0.43</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">],</span> <span class="c1"># Your     (x^1)</span>
   <span class="p">[</span><span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.87</span><span class="p">,</span> <span class="mf">0.66</span><span class="p">],</span> <span class="c1"># journey  (x^2)</span>
   <span class="p">[</span><span class="mf">0.57</span><span class="p">,</span> <span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.64</span><span class="p">],</span> <span class="c1"># starts   (x^3)</span>
   <span class="p">[</span><span class="mf">0.22</span><span class="p">,</span> <span class="mf">0.58</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">],</span> <span class="c1"># with     (x^4)</span>
   <span class="p">[</span><span class="mf">0.77</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">],</span> <span class="c1"># one      (x^5)</span>
   <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">]]</span> <span class="c1"># step     (x^6)</span>
<span class="p">)</span>
<span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">inputs</span><span class="p">,</span> <span class="n">inputs</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([2, 6, 3])
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [120]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">context_length</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># This is the number of tokens = 6</span>
<span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span>
<span class="n">mha</span> <span class="o">=</span> <span class="n">MultiHeadAttentionWrapper</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">context_length</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">context_vecs</span> <span class="o">=</span> <span class="n">mha</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">context_vecs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"context_vecs.shape:"</span><span class="p">,</span> <span class="n">context_vecs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],
         [-0.5874,  0.0058,  0.5891,  0.3257],
         [-0.6300, -0.0632,  0.6202,  0.3860],
         [-0.5675, -0.0843,  0.5478,  0.3589],
         [-0.5526, -0.0981,  0.5321,  0.3428],
         [-0.5299, -0.1081,  0.5077,  0.3493]],

        [[-0.4519,  0.2216,  0.4772,  0.1063],
         [-0.5874,  0.0058,  0.5891,  0.3257],
         [-0.6300, -0.0632,  0.6202,  0.3860],
         [-0.5675, -0.0843,  0.5478,  0.3589],
         [-0.5526, -0.0981,  0.5321,  0.3428],
         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=&lt;CatBackward0&gt;)
context_vecs.shape: torch.Size([2, 6, 4])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>The first dimension of the resulting context_vecs tensor is 2 since we have two input texts
(the input texts are duplicated, which is why the context vectors are exactly the same for
those).</p>
<p>The second dimension refers to the 6 tokens in each input. The third dimension
refers to the 4-dimensional embedding of each token.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
In this section, we implemented a MultiHeadAttentionWrapper that combined multiple
single-head attention modules.
<p>However, note that these are processed sequentially via
[head(x) for head in self.heads] in the forward method.</p>
<p>We can improve this
implementation by processing the heads in parallel.</p>
<p>One way to achieve this is by
computing the outputs for all attention heads simultaneously via matrix multiplication, as
we will explore in the next section.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="IMPLEMENTING-MULTI-HEAD-ATTENTION-WITH-WEIGHT-SPLITS">IMPLEMENTING MULTI-HEAD ATTENTION WITH WEIGHT SPLITS<a class="anchor-link" href="#IMPLEMENTING-MULTI-HEAD-ATTENTION-WITH-WEIGHT-SPLITS">¶</a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Instead of maintaining two separate classes, MultiHeadAttentionWrapper and
CausalAttention, we can combine both of these concepts into a single
MultiHeadAttention class.</p>
<p>Also, in addition to just merging the
MultiHeadAttentionWrapper with the CausalAttention code, we will make some other
modifications to implement multi-head attention more efficiently.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>In the MultiHeadAttentionWrapper, multiple heads are implemented by creating a list
of CausalAttention objects (self.heads), each representing a separate attention head.</p>
<p>The CausalAttention class independently performs the attention mechanism, and the
results from each head are concatenated.</p>
<p>In contrast, the following MultiHeadAttention
class integrates the multi-head functionality within a single class.</p>
<p>It splits the input into
multiple heads by reshaping the projected query, key, and value tensors and then combines
the results from these heads after computing attention.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Let's take a look at the MultiHeadAttention class before we discuss it further:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [121]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">context_length</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">qkv_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">assert</span> <span class="p">(</span><span class="n">d_out</span> <span class="o">%</span> <span class="n">num_heads</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> \
            <span class="s2">"d_out must be divisible by num_heads"</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">d_out</span> <span class="o">=</span> <span class="n">d_out</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span> <span class="o">=</span> <span class="n">d_out</span> <span class="o">//</span> <span class="n">num_heads</span> <span class="c1"># Reduce the projection dim to match desired output dim</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">W_query</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_key</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_out</span><span class="p">,</span> <span class="n">d_out</span><span class="p">)</span>  <span class="c1"># Linear layer to combine head outputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">"mask"</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">context_length</span><span class="p">,</span> <span class="n">context_length</span><span class="p">),</span>
                       <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">num_tokens</span><span class="p">,</span> <span class="n">d_in</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_key</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># Shape: (b, num_tokens, d_out)</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_query</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># We implicitly split the matrix by adding a `num_heads` dimension</span>
        <span class="c1"># Unroll last dim: (b, num_tokens, d_out) -&gt; (b, num_tokens, num_heads, head_dim)</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="n">keys</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">num_tokens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">num_tokens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="n">queries</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">num_tokens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span>

        <span class="c1"># Transpose: (b, num_tokens, num_heads, head_dim) -&gt; (b, num_heads, num_tokens, head_dim)</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="n">keys</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="n">queries</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Compute scaled dot-product attention (aka self-attention) with a causal mask</span>
        <span class="n">attn_scores</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">@</span> <span class="n">keys</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># Dot product for each head</span>

        <span class="c1"># Original mask truncated to the number of tokens and converted to boolean</span>
        <span class="n">mask_bool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()[:</span><span class="n">num_tokens</span><span class="p">,</span> <span class="p">:</span><span class="n">num_tokens</span><span class="p">]</span>

        <span class="c1"># Use the mask to fill attention scores</span>
        <span class="n">attn_scores</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">mask_bool</span><span class="p">,</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>

        <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn_scores</span> <span class="o">/</span> <span class="n">keys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">attn_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">)</span>

        <span class="c1"># Shape: (b, num_tokens, num_heads, head_dim)</span>
        <span class="n">context_vec</span> <span class="o">=</span> <span class="p">(</span><span class="n">attn_weights</span> <span class="o">@</span> <span class="n">values</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Combine heads, where self.d_out = self.num_heads * self.head_dim</span>
        <span class="n">context_vec</span> <span class="o">=</span> <span class="n">context_vec</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">num_tokens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_out</span><span class="p">)</span>
        <span class="n">context_vec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span><span class="p">(</span><span class="n">context_vec</span><span class="p">)</span> <span class="c1"># optional projection</span>

        <span class="k">return</span> <span class="n">context_vec</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Step 1: Reduce the projection dim to match desired output dim</p>
<p>Step 2: Use a Linear layer to combine head outputs</p>
<p>Step 3: Tensor shape: (b, num_tokens, d_out)</p>
<p>Step 4: We implicitly split the matrix by adding a <code>num_heads</code> dimension. Then we unroll last dim: (b,
num_tokens, d_out) -&gt; (b, num_tokens, num_heads, head_dim)</p>
<p>Step 5: Transpose from shape (b, num_tokens, num_heads, head_dim) to (b, num_heads, num_tokens, head_dim)</p>
<p>Step 6: Compute dot product for each head</p>
<p>Step 7: Mask truncated to the number of tokens</p>
<p>Step 8: Use the mask to fill attention scores</p>
<p>Step 9: Tensor shape: (b, num_tokens, n_heads, head_dim)</p>
<p>Step 10: Combine heads, where self.d_out = self.num_heads * self.head_dim</p>
<p>Step 11: Add an optional linear projection</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>The MultiHeadAttention class can be used similar to the SelfAttention and
CausalAttention classes we implemented earlier:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [122]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>

<span class="c1"># Define the tensor with 3 rows and 6 columns</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
    <span class="p">[[</span><span class="mf">0.43</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.87</span><span class="p">,</span> <span class="mf">0.66</span><span class="p">],</span>  <span class="c1"># Row 1</span>
     <span class="p">[</span><span class="mf">0.57</span><span class="p">,</span> <span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.64</span><span class="p">,</span> <span class="mf">0.22</span><span class="p">,</span> <span class="mf">0.58</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">],</span>  <span class="c1"># Row 2</span>
     <span class="p">[</span><span class="mf">0.77</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">]]</span>  <span class="c1"># Row 3</span>
<span class="p">)</span>

<span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">inputs</span><span class="p">,</span> <span class="n">inputs</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">batch_size</span><span class="p">,</span> <span class="n">context_length</span><span class="p">,</span> <span class="n">d_in</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">shape</span>
<span class="n">d_out</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">mha</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">context_length</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">context_vecs</span> <span class="o">=</span> <span class="n">mha</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">context_vecs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"context_vecs.shape:"</span><span class="p">,</span> <span class="n">context_vecs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([2, 3, 6])
tensor([[[ 0.1569, -0.0873,  0.0210,  0.0215, -0.3243, -0.2518],
         [ 0.1117, -0.0547,  0.0406, -0.0213, -0.3251, -0.2993],
         [ 0.1196, -0.0491,  0.0318, -0.0635, -0.2788, -0.2578]],

        [[ 0.1569, -0.0873,  0.0210,  0.0215, -0.3243, -0.2518],
         [ 0.1117, -0.0547,  0.0406, -0.0213, -0.3251, -0.2993],
         [ 0.1196, -0.0491,  0.0318, -0.0635, -0.2788, -0.2578]]],
       grad_fn=&lt;ViewBackward0&gt;)
context_vecs.shape: torch.Size([2, 3, 6])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can see based on the results, the output dimension is directly controlled by the
d_out argument:</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>For comparison, the smallest GPT-2 model (117 million parameters) has 12 attention
heads and a context vector embedding size of 768.</p>
<p>The largest GPT-2 model (1.5 billion
parameters) has 25 attention heads and a context vector embedding size of 1600.</p>
<p>Note
that the embedding sizes of the token inputs and context embeddings are the same in GPT
models (d_in = d_out).</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="IMPLEMENTING-A-GPT-MODEL-FROM-SCRATCH-TO-GENERATE-TEXT">IMPLEMENTING A GPT MODEL FROM SCRATCH TO GENERATE TEXT<a class="anchor-link" href="#IMPLEMENTING-A-GPT-MODEL-FROM-SCRATCH-TO-GENERATE-TEXT">¶</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [124]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">GPT_CONFIG_124M</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"vocab_size"</span><span class="p">:</span> <span class="mi">50257</span><span class="p">,</span>    <span class="c1"># Vocabulary size</span>
    <span class="s2">"context_length"</span><span class="p">:</span> <span class="mi">1024</span><span class="p">,</span> <span class="c1"># Context length</span>
    <span class="s2">"emb_dim"</span><span class="p">:</span> <span class="mi">768</span><span class="p">,</span>         <span class="c1"># Embedding dimension</span>
    <span class="s2">"n_heads"</span><span class="p">:</span> <span class="mi">12</span><span class="p">,</span>          <span class="c1"># Number of attention heads</span>
    <span class="s2">"n_layers"</span><span class="p">:</span> <span class="mi">12</span><span class="p">,</span>         <span class="c1"># Number of layers</span>
    <span class="s2">"drop_rate"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>       <span class="c1"># Dropout rate</span>
    <span class="s2">"qkv_bias"</span><span class="p">:</span> <span class="kc">False</span>       <span class="c1"># Query-Key-Value bias</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="GPT-ARCHITECTURE-PART-1:-DUMMY-GPT-MODEL-CLASS">GPT ARCHITECTURE PART 1: DUMMY GPT MODEL CLASS<a class="anchor-link" href="#GPT-ARCHITECTURE-PART-1:-DUMMY-GPT-MODEL-CLASS">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Step 1: Use a placeholder for TransformerBlock</p>
<p>Step 2: Use a placeholder for LayerNorm</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [125]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>


<span class="k">class</span> <span class="nc">DummyGPTModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tok_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"vocab_size"</span><span class="p">],</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">"emb_dim"</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"context_length"</span><span class="p">],</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">"emb_dim"</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"drop_rate"</span><span class="p">])</span>

        <span class="c1"># Use a placeholder for TransformerBlock</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trf_blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span><span class="n">DummyTransformerBlock</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"n_layers"</span><span class="p">])])</span>

        <span class="c1"># Use a placeholder for LayerNorm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_norm</span> <span class="o">=</span> <span class="n">DummyLayerNorm</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"emb_dim"</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span>
            <span class="n">cfg</span><span class="p">[</span><span class="s2">"emb_dim"</span><span class="p">],</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">"vocab_size"</span><span class="p">],</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_idx</span><span class="p">):</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span> <span class="o">=</span> <span class="n">in_idx</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">tok_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tok_emb</span><span class="p">(</span><span class="n">in_idx</span><span class="p">)</span>
        <span class="n">pos_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_emb</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">in_idx</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tok_embeds</span> <span class="o">+</span> <span class="n">pos_embeds</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_emb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trf_blocks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>


<span class="k">class</span> <span class="nc">DummyTransformerBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># A simple placeholder</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># This block does nothing and just returns its input.</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">DummyLayerNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># The parameters here are just to mimic the LayerNorm interface.</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># This layer does nothing and just returns its input.</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The DummyGPTModel class in this code defines a simplified version of a GPT-like model using
PyTorch's neural network module (nn.Module).</p>
<p>The model architecture in the
DummyGPTModel class consists of token and positional embeddings, dropout, a series of
transformer blocks (DummyTransformerBlock), a final layer normalization
(DummyLayerNorm), and a linear output layer (out_head).</p>
<p>The configuration is passed in via
a Python dictionary, for instance, the GPT_CONFIG_124M dictionary we created earlier.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The forward method describes the data flow through the model: it computes token and
positional embeddings for the input indices, applies dropout, processes the data through
the transformer blocks, applies normalization, and finally produces logits with the linear
output layer.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The code above is already functional, as we will see later in this section after we prepare
the input data.</p>
<p>However, for now, note in the code above that we have used placeholders
(DummyLayerNorm and DummyTransformerBlock) for the transformer block and layer
normalization, which we will develop in later sections</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Next, we will prepare the input data and initialize a new GPT model to illustrate its
usage.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="STEP-1:-TOKENIZATION">STEP 1: TOKENIZATION<a class="anchor-link" href="#STEP-1:-TOKENIZATION">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [126]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tiktoken</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
<span class="n">batch</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">txt1</span> <span class="o">=</span> <span class="s2">"Every effort moves you"</span>
<span class="n">txt2</span> <span class="o">=</span> <span class="s2">"Every day holds a"</span>
<span class="n">batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">txt1</span><span class="p">)))</span>
<span class="n">batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">txt2</span><span class="p">)))</span>
<span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[6109, 3626, 6100,  345],
        [6109, 1110, 6622,  257]])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="STEP-2:-CREATE-AN-INSTANCE-OF-DUMMYGPTMODEL">STEP 2: CREATE AN INSTANCE OF DUMMYGPTMODEL<a class="anchor-link" href="#STEP-2:-CREATE-AN-INSTANCE-OF-DUMMYGPTMODEL">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [127]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DummyGPTModel</span><span class="p">(</span><span class="n">GPT_CONFIG_124M</span><span class="p">)</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Output shape:"</span><span class="p">,</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Output shape: torch.Size([2, 4, 50257])
tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],
         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],
         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],
         [ 0.0139,  1.6754, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],

        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],
         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],
         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],
         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],
       grad_fn=&lt;UnsafeViewBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The output tensor has two rows corresponding to the two text samples. Each text sample
consists of 4 tokens; each token is a 50,257-dimensional vector, which matches the size of
the tokenizer's vocabulary.</p>
<p>The embedding has 50,257 dimensions because each of these dimensions refers to a
unique token in the vocabulary. At the end of this chapter, when we implement the
postprocessing code, we will convert these 50,257-dimensional vectors back into token IDs,
which we can then decode into words.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Now that we have taken a top-down look at the GPT architecture and its in- and outputs,
we will code the individual placeholders in the upcoming sections, starting with the real
layer normalization class that will replace the DummyLayerNorm in the previous code.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="GPT-ARCHITECTURE-PART-2:-LAYER-NORMALIZATION">GPT ARCHITECTURE PART 2: LAYER NORMALIZATION<a class="anchor-link" href="#GPT-ARCHITECTURE-PART-2:-LAYER-NORMALIZATION">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Explanation-with-a-simple-example">Explanation with a simple example<a class="anchor-link" href="#Explanation-with-a-simple-example">¶</a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [128]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">batch_example</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="c1">#A</span>
<span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">batch_example</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],
        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],
       grad_fn=&lt;ReluBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>The neural network layer we have coded consists of a Linear layer followed by a non-linear
activation function, ReLU (short for Rectified Linear Unit), which is a standard activation
function in neural networks.</p>
<p>If you are unfamiliar with ReLU, it simply thresholds negative
inputs to 0, ensuring that a layer outputs only positive values, which explains why the
resulting layer output does not contain any negative values.</p>
<p>(Note that we will use another,
more sophisticated activation function in GPT, which we will introduce in the next section).</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Before we apply layer normalization to these outputs, let's examine the mean and
variance:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [129]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">mean</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">var</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Mean:</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Variance:</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Mean:
 tensor([[0.1324],
        [0.2170]], grad_fn=&lt;MeanBackward1&gt;)
Variance:
 tensor([[0.0231],
        [0.0398]], grad_fn=&lt;VarBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The first row in the mean tensor above contains the mean value for the first input row, and
the second output row contains the mean for the second input row.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Using keepdim=True in operations like mean or variance calculation ensures that the
output tensor retains the same number of dimensions as the input tensor, even though the
operation reduces the tensor along the dimension specified via dim.</p>
<p>For instance, without
keepdim=True, the returned mean tensor would be a 2-dimensional vector [0.1324,
0.2170] instead of a 2×1-dimensional matrix [[0.1324], [0.2170]].</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>For a 2D tensor (like a matrix), using dim=-1 for operations such as
mean or variance calculation is the same as using dim=1.</p>
<p>This is because -1 refers to the
tensor's last dimension, which corresponds to the columns in a 2D tensor.</p>
<p>Later, when
adding layer normalization to the GPT model, which produces 3D tensors with shape
[batch_size, num_tokens, embedding_size], we can still use dim=-1 for normalization
across the last dimension, avoiding a change from dim=1 to dim=2.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Next, let us apply layer normalization to the layer outputs we obtained earlier. The
operation consists of subtracting the mean and dividing by the square root of the variance
(also known as standard deviation):</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [130]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">out_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">out</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">out_norm</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">var</span> <span class="o">=</span> <span class="n">out_norm</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Normalized layer outputs:</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">out_norm</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Mean:</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Variance:</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Normalized layer outputs:
 tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],
        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],
       grad_fn=&lt;DivBackward0&gt;)
Mean:
 tensor([[-5.9605e-08],
        [ 1.9868e-08]], grad_fn=&lt;MeanBackward1&gt;)
Variance:
 tensor([[1.0000],
        [1.0000]], grad_fn=&lt;VarBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Note that the value 2.9802e-08 in the output tensor is the scientific notation for 2.9802 ×
10-8, which is 0.0000000298 in decimal form. This value is very close to 0, but it is not
exactly 0 due to small numerical errors that can accumulate because of the finite precision
with which computers represent numbers.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>To improve readability, we can also turn off the scientific notation when printing tensor
values by setting sci_mode to False:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [131]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">sci_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Mean:</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Variance:</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Mean:
 tensor([[    -0.0000],
        [     0.0000]], grad_fn=&lt;MeanBackward1&gt;)
Variance:
 tensor([[1.0000],
        [1.0000]], grad_fn=&lt;VarBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Let's now encapsulate this process in a PyTorch module that we can use in the GPT
model later:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [132]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">LayerNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-5</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">emb_dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shift</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">emb_dim</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">unbiased</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">norm_x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">*</span> <span class="n">norm_x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shift</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>This specific implementation of layer Normalization operates on the last dimension of the
input tensor x, which represents the embedding dimension (emb_dim).</p>
<p>The variable eps is a
small constant (epsilon) added to the variance to prevent division by zero during
normalization.</p>
<p>The scale and shift are two trainable parameters (of the same dimension
as the input) that the LLM automatically adjusts during training if it is determined that
doing so would improve the model's performance on its training task.</p>
<p>This allows the model
to learn appropriate scaling and shifting that best suit the data it is processing.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><em>A small note on biased variance</em></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>In our variance calculation method, we have opted for an implementation detail by
setting unbiased=False.</p>
<p>For those curious about what this means, in the variance
calculation, we divide by the number of inputs n in the variance formula.</p>
<p>This approach does not apply Bessel's correction, which typically uses n-1 instead of n in
the denominator to adjust for bias in sample variance estimation.</p>
<p>This decision results in a so-called biased estimate of the variance.</p>
<p>For large-scale language
models (LLMs), where the embedding dimension n is significantly large, the
difference between using n and n-1 is practically negligible.</p>
<p>We chose this approach to ensure compatibility with the GPT-2 model's normalization layers and because it
reflects TensorFlow's default behavior, which was used to implement the original GPT2 model.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Let's now try the LayerNorm module in practice and apply it to the batch input:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [133]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">ln</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">emb_dim</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">out_ln</span> <span class="o">=</span> <span class="n">ln</span><span class="p">(</span><span class="n">batch_example</span><span class="p">)</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">out_ln</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">var</span> <span class="o">=</span> <span class="n">out_ln</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">unbiased</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Mean:</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Variance:</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Mean:
 tensor([[    -0.0000],
        [     0.0000]], grad_fn=&lt;MeanBackward1&gt;)
Variance:
 tensor([[1.0000],
        [1.0000]], grad_fn=&lt;VarBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can see based on the results, the layer normalization code works as expected and
normalizes the values of each of the two inputs such that they have a mean of 0 and a
variance of 1:</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="GPT-ARCHITECTURE-PART-3:-FEEDFORWARD-NEURAL-NETWORK-WITH-GELU-ACTIVATION">GPT ARCHITECTURE PART 3: FEEDFORWARD NEURAL NETWORK WITH GELU ACTIVATION<a class="anchor-link" href="#GPT-ARCHITECTURE-PART-3:-FEEDFORWARD-NEURAL-NETWORK-WITH-GELU-ACTIVATION">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Let's implement the GELU activation function approximation used by GPT-2:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [135]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">GELU</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span> <span class="o">*</span>
            <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.044715</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>To get an idea of what this GELU function looks like and how it compares to the ReLU
function, let's plot these functions side by side:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [136]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">gelu</span><span class="p">,</span> <span class="n">relu</span> <span class="o">=</span> <span class="n">GELU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

<span class="c1"># Some sample data</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y_gelu</span><span class="p">,</span> <span class="n">y_relu</span> <span class="o">=</span> <span class="n">gelu</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">([</span><span class="n">y_gelu</span><span class="p">,</span> <span class="n">y_relu</span><span class="p">],</span> <span class="p">[</span><span class="s2">"GELU"</span><span class="p">,</span> <span class="s2">"ReLU"</span><span class="p">]),</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2"> activation function"</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"x"</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2">(x)"</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can see in the resulting plot, ReLU is a piecewise linear function that
outputs the input directly if it is positive; otherwise, it outputs zero.</p>
<p>GELU is a smooth, nonlinear function that approximates ReLU but with a non-zero gradient for negative values.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The smoothness of GELU, as shown in the above figure, can lead to better optimization properties
during training, as it allows for more nuanced adjustments to the model's parameters.</p>
<p>In contrast, ReLU has a sharp corner at zero, which can sometimes make optimization harder,
especially in networks that are very deep or have complex architectures.</p>
<p>Moreover, unlike RELU, which outputs zero for any negative input, GELU allows for a small, non-zero output
for negative values.</p>
<p>This characteristic means that during the training process, neurons that
receive negative input can still contribute to the learning process, albeit to a lesser extent
than positive inputs.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Next, let's use the GELU function to implement the small neural network module,
FeedForward, that we will be using in the LLM's transformer block later:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [137]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">FeedForward</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"emb_dim"</span><span class="p">],</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">"emb_dim"</span><span class="p">]),</span>
            <span class="n">GELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">"emb_dim"</span><span class="p">],</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">"emb_dim"</span><span class="p">]),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [138]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">GPT_CONFIG_124M</span><span class="p">[</span><span class="s2">"emb_dim"</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>768
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can see in the preceding code, the FeedForward module is a small neural network
consisting of two Linear layers and a GELU activation function.</p>
<p>In the 124 million parameter GPT model, it receives the input batches with tokens that have an embedding
size of 768 each via the GPT_CONFIG_124M dictionary where GPT_CONFIG_124M["emb_dim"]
= 768.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Let's use the GELU function to implement the small neural network module,
FeedForward, that we will be using in the LLM's transformer block later:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [139]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">ffn</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">GPT_CONFIG_124M</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span> <span class="c1">#A</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">ffn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([2, 3, 768])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The FeedForward module we implemented in this section plays a crucial role in enhancing
the model's ability to learn from and generalize the data.</p>
<p>Although the input and output dimensions of this module are the same, it internally expands the embedding dimension
into a higher-dimensional space through the first linear layer.</p>
<p>This expansion is followed by a non-linear GELU activation, and then a contraction back to
the original dimension with the second linear transformation.</p>
<p>Such a design allows for the
exploration of a richer representation space.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Moreover, the uniformity in input and output dimensions simplifies the architecture by
enabling the stacking of multiple layers, as we will do later, without the need to adjust
dimensions between them, thus making the model more scalable.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="GPT-ARCHITECTURE-PART-4:-SHORTCUT-CONNECTIONS">GPT ARCHITECTURE PART 4: SHORTCUT CONNECTIONS<a class="anchor-link" href="#GPT-ARCHITECTURE-PART-4:-SHORTCUT-CONNECTIONS">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Let us see how we can add shortcut connections to the forward method:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [140]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">ExampleDeepNeuralNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_sizes</span><span class="p">,</span> <span class="n">use_shortcut</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_shortcut</span> <span class="o">=</span> <span class="n">use_shortcut</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">GELU</span><span class="p">()),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="n">GELU</span><span class="p">()),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="mi">3</span><span class="p">]),</span> <span class="n">GELU</span><span class="p">()),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="mi">4</span><span class="p">]),</span> <span class="n">GELU</span><span class="p">()),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="mi">5</span><span class="p">]),</span> <span class="n">GELU</span><span class="p">())</span>
        <span class="p">])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="c1"># Compute the output of the current layer</span>
            <span class="n">layer_output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="c1"># Check if shortcut can be applied</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_shortcut</span> <span class="ow">and</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">layer_output</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">layer_output</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">layer_output</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>The code implements a deep neural network with 5 layers, each consisting of a Linear
layer and a GELU activation function.</p>
<p>In the forward pass, we iteratively pass the input
through the layers and optionally add the shortcut connections  if
the self.use_shortcut attribute is set to True.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Let's use this code to first initialize a neural network without shortcut connections. Here,
each layer will be initialized such that it accepts an example with 3 input values and returns
3 output values. The last layer returns a single output value:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [141]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">sample_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span> <span class="c1"># specify random seed for the initial weights for reproducibility</span>
<span class="n">model_without_shortcut</span> <span class="o">=</span> <span class="n">ExampleDeepNeuralNetwork</span><span class="p">(</span>
<span class="n">layer_sizes</span><span class="p">,</span> <span class="n">use_shortcut</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Next, we implement a function that computes the gradients in the the model's backward
pass:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [142]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">print_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># Forward pass</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">]])</span>

    <span class="c1"># Calculate loss based on how close the target</span>
    <span class="c1"># and output are</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

    <span class="c1"># Backward pass to calculate the gradients</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="s1">'weight'</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
            <span class="c1"># Print the mean absolute gradient of the weights</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> has gradient mean of </span><span class="si">{</span><span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>In the preceding code, we specify a loss function that computes how close the model output
and a user-specified target (here, for simplicity, the value 0) are.</p>
<p>Then, when calling loss.backward(), PyTorch computes the loss gradient for each layer in the model.</p>
<p>We can iterate through the weight parameters via model.named_parameters().</p>
<p>Suppose we have a 3×3 weight parameter matrix for a given layer.</p>
<p>In that case, this layer will have 3×3 gradient values, and we print the mean absolute gradient of these 3×3 gradient values to
obtain a single gradient value per layer to compare the gradients between layers more
easily.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>In short, the .backward() method is a convenient method in PyTorch that computes loss
gradients, which are required during model training, without implementing the math for the
gradient calculation ourselves, thereby making working with deep neural networks much
more accessible.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
<p>Let's now use the print_gradients function and apply it to the model without skip
connections:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [143]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">print_gradients</span><span class="p">(</span><span class="n">model_without_shortcut</span><span class="p">,</span> <span class="n">sample_input</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>layers.0.0.weight has gradient mean of 0.00020173587836325169
layers.1.0.weight has gradient mean of 0.00012011159560643137
layers.2.0.weight has gradient mean of 0.0007152039906941354
layers.3.0.weight has gradient mean of 0.0013988736318424344
layers.4.0.weight has gradient mean of 0.005049645435065031
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
As we can see based on the output of the print_gradients function, the gradients become
smaller as we progress from the last layer (layers.4) to the first layer (layers.0), which
is a phenomenon called the vanishing gradient problem.
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
Let's now instantiate a model with skip connections and see how it compares:
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [144]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">model_with_shortcut</span> <span class="o">=</span> <span class="n">ExampleDeepNeuralNetwork</span><span class="p">(</span>
<span class="n">layer_sizes</span><span class="p">,</span> <span class="n">use_shortcut</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">print_gradients</span><span class="p">(</span><span class="n">model_with_shortcut</span><span class="p">,</span> <span class="n">sample_input</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>layers.0.0.weight has gradient mean of 0.22169792652130127
layers.1.0.weight has gradient mean of 0.20694106817245483
layers.2.0.weight has gradient mean of 0.32896995544433594
layers.3.0.weight has gradient mean of 0.2665732204914093
layers.4.0.weight has gradient mean of 1.3258540630340576
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
As we can see, based on the output, the last layer (layers.4) still has a larger gradient
than the other layers.
<p>However, the gradient value stabilizes as we progress towards the
first layer (layers.0) and doesn't shrink to a vanishingly small value.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>In conclusion, shortcut connections are important for overcoming the limitations posed
by the vanishing gradient problem in deep neural networks.</p>
<p>Shortcut connections are a core building block of very large models such as LLMs, and they will help facilitate more effective
training by ensuring consistent gradient flow across layers when we train the GPT model</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="GPT-ARCHITECTURE-PART-5:-CODING-ATTENTION-AND-LINEAR-LAYERS-IN-A-TRANSFORMER-BLOCK">GPT ARCHITECTURE PART 5: CODING ATTENTION AND LINEAR LAYERS IN A TRANSFORMER BLOCK<a class="anchor-link" href="#GPT-ARCHITECTURE-PART-5:-CODING-ATTENTION-AND-LINEAR-LAYERS-IN-A-TRANSFORMER-BLOCK">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
Let us code a transformer block as follows:
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Step 1: Shortcut connection for attention block</p>
<p>Step 2:  Shortcut connection for feed forward block</p>
<p>Step 3: Add the original input back</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [145]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">TransformerBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">att</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span>
            <span class="n">d_in</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"emb_dim"</span><span class="p">],</span>
            <span class="n">d_out</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"emb_dim"</span><span class="p">],</span>
            <span class="n">context_length</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"context_length"</span><span class="p">],</span>
            <span class="n">num_heads</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"n_heads"</span><span class="p">],</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"drop_rate"</span><span class="p">],</span>
            <span class="n">qkv_bias</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"qkv_bias"</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ff</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"emb_dim"</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"emb_dim"</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop_shortcut</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"drop_rate"</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Shortcut connection for attention block</span>
        <span class="n">shortcut</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Shape [batch_size, num_tokens, emb_size]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_shortcut</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">shortcut</span>  <span class="c1"># Add the original input back</span>

        <span class="c1"># Shortcut connection for feed forward block</span>
        <span class="n">shortcut</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_shortcut</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">shortcut</span>  <span class="c1"># Add the original input back</span>

        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The given code defines a TransformerBlock class in PyTorch that includes a multi-head
attention mechanism (MultiHeadAttention) and a feed forward network (FeedForward),
both configured based on a provided configuration dictionary (cfg), such as
GPT_CONFIG_124M</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Layer normalization (LayerNorm) is applied before each of these two components, and
dropout is applied after them to regularize the model and prevent overfitting.</p>
<p>This is also known as Pre-LayerNorm.</p>
<p>Older architectures, such as the original transformer model,
applied layer normalization after the self-attention and feed-forward networks instead,
known as Post-LayerNorm, which often leads to worse training dynamics.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The class also implements the forward pass, where each component is followed by a
shortcut connection that adds the input of the block to its output. This critical feature helps
gradients flow through the network during training and improves the learning of deep
models</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
Using the GPT_CONFIG_124M dictionary we defined earlier, let's instantiate a transformer
block and feed it some sample data
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Create sample input of shape [batch_size, num_tokens, emb_dim]</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [146]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span> <span class="c1">#A</span>
<span class="n">block</span> <span class="o">=</span> <span class="n">TransformerBlock</span><span class="p">(</span><span class="n">GPT_CONFIG_124M</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Input shape:"</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Output shape:"</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Input shape: torch.Size([2, 4, 768])
Output shape: torch.Size([2, 4, 768])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can see from the code output, the transformer block maintains the input dimensions
in its output, indicating that the transformer architecture processes sequences of data
without altering their shape throughout the network.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The preservation of shape throughout the transformer block architecture is not incidental
but a crucial aspect of its design.</p>
<p>This design enables its effective application across a wide
range of sequence-to-sequence tasks, where each output vector directly corresponds to an
input vector, maintaining a one-to-one relationship.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>However, the output is a context vector
that encapsulates information from the entire input sequence.</p>
<p>This means that while the physical dimensions of the sequence (length and feature size)
remain unchanged as it passes through the transformer block, the content of each output
vector is re-encoded to integrate contextual information from across the entire input
sequence.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="GPT-ARCHITECTURE-PART-6:-ENTIRE-GPT-MODEL-ARCHITECTURE-IMPLEMENTATION">GPT ARCHITECTURE PART 6: ENTIRE GPT MODEL ARCHITECTURE IMPLEMENTATION<a class="anchor-link" href="#GPT-ARCHITECTURE-PART-6:-ENTIRE-GPT-MODEL-ARCHITECTURE-IMPLEMENTATION">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>The device setting will allow us to train the model on a CPU or GPU, depending on which device the input
data sits</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [147]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">GPTModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tok_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"vocab_size"</span><span class="p">],</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">"emb_dim"</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"context_length"</span><span class="p">],</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">"emb_dim"</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"drop_rate"</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trf_blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span><span class="n">TransformerBlock</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"n_layers"</span><span class="p">])])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">final_norm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"emb_dim"</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span>
            <span class="n">cfg</span><span class="p">[</span><span class="s2">"emb_dim"</span><span class="p">],</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">"vocab_size"</span><span class="p">],</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_idx</span><span class="p">):</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span> <span class="o">=</span> <span class="n">in_idx</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">tok_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tok_emb</span><span class="p">(</span><span class="n">in_idx</span><span class="p">)</span>
        <span class="n">pos_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_emb</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">in_idx</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tok_embeds</span> <span class="o">+</span> <span class="n">pos_embeds</span>  <span class="c1"># Shape [batch_size, num_tokens, emb_size]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_emb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trf_blocks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The <strong>init</strong> constructor of this GPTModel class initializes the token and positional
embedding layers using the configurations passed in via a Python dictionary, cfg.</p>
<p>These
embedding layers are responsible for converting input token indices into dense vectors and
adding positional information.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Next, the <strong>init</strong> method creates a sequential stack of TransformerBlock modules
equal to the number of layers specified in cfg.</p>
<p>Following the transformer blocks, a
LayerNorm layer is applied, standardizing the outputs from the transformer blocks to
stabilize the learning process.</p>
<p>Finally, a linear output head without bias is defined, which
projects the transformer's output into the vocabulary space of the tokenizer to generate
logits for each token in the vocabulary.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The forward method takes a batch of input token indices, computes their embeddings,
applies the positional embeddings, passes the sequence through the transformer blocks,
normalizes the final output, and then computes the logits, representing the next token's
unnormalized probabilities. We will convert these logits into tokens and text outputs in the
next section.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
Let's now initialize the 124 million parameter GPT model using the GPT_CONFIG_124M
dictionary we pass into the cfg parameter and feed it with the batch text input we created
at the beginning of this chapter:
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [148]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPTModel</span><span class="p">(</span><span class="n">GPT_CONFIG_124M</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Input batch:</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Output shape:"</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Input batch:
 tensor([[6109, 3626, 6100,  345],
        [6109, 1110, 6622,  257]])

Output shape: torch.Size([2, 4, 50257])
tensor([[[ 0.3613,  0.4222, -0.0711,  ...,  0.3483,  0.4661, -0.2838],
         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],
         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],
         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],

        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],
         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],
         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],
         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],
       grad_fn=&lt;UnsafeViewBackward0&gt;)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can see, the output tensor has the shape [2, 4, 50257], since we passed in 2 input
texts with 4 tokens each. The last dimension, 50,257, corresponds to the vocabulary size of
the tokenizer. In the next section, we will see how to convert each of these 50,257-
dimensional output vectors back into tokens.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
Using the numel() method, short for "number of elements," we can collect the total
number of parameters in the model's parameter tensors:
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [149]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">total_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total number of parameters: </span><span class="si">{</span><span class="n">total_params</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Total number of parameters: 163,009,536
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-danger">
Earlier, we spoke of initializing a 124
million parameter GPT model, so why is the actual number of parameters 163 million, as
shown in the preceding code output?
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>The reason is a concept called weight tying that is used in the original GPT-2
architecture, which means that the original GPT-2 architecture is reusing the weights from
the token embedding layer in its output layer.</p>
<p>To understand what this means, let's take a
look at the shapes of the token embedding layer and linear output layer that we initialized
on the model via the GPTModel earlier:</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [150]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"Token embedding layer shape:"</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">tok_emb</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Output layer shape:"</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">out_head</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Token embedding layer shape: torch.Size([50257, 768])
Output layer shape: torch.Size([50257, 768])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can see based on the print outputs, the weight tensors for both these layers have the
same shape:</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
The token embedding and output layers are very large due to the number of rows for the
50,257 in the tokenizer's vocabulary. Let's remove the output layer parameter count from
the total GPT-2 model count according to the weight tying:
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [151]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">total_params_gpt2</span> <span class="o">=</span> <span class="n">total_params</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">out_head</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of trainable parameters considering weight tying: </span><span class="si">{</span><span class="n">total_params_gpt2</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Number of trainable parameters considering weight tying: 124,412,160
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can see, the model is now only 124 million parameters large, matching the original
size of the GPT-2 model.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>Weight tying reduces the overall memory footprint and computational complexity of the
model. However, in my experience, using separate token embedding and output layers
results in better training and model performance; hence, we are using separate layers in
our GPTModel implementation. The same is true for modern LLMs.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
Lastly, let us compute the memory requirements of the 163 million parameters in our
GPTModel object:
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [152]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">total_size_bytes</span> <span class="o">=</span> <span class="n">total_params</span> <span class="o">*</span> <span class="mi">4</span> <span class="c1">#A</span>
<span class="n">total_size_mb</span> <span class="o">=</span> <span class="n">total_size_bytes</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">)</span> <span class="c1">#B</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total size of the model: </span><span class="si">{</span><span class="n">total_size_mb</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> MB"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Total size of the model: 621.83 MB
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>In conclusion, by calculating the memory requirements for the 163 million parameters in
our GPTModel object and assuming each parameter is a 32-bit float taking up 4 bytes, we
find that the total size of the model amounts to 621.83 MB, illustrating the relatively large
storage capacity required to accommodate even relatively small LLMs.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>In this section, we implemented the GPTModel architecture and saw that it outputs
numeric tensors of shape [batch_size, num_tokens, vocab_size]. In the next section,
we will write the code to convert these output tensors into text.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="GPT-ARCHITECTURE-PART-7:-GENERATING-TEXT-FROM-OUTPUT-TOKENS">GPT ARCHITECTURE PART 7: GENERATING TEXT FROM OUTPUT TOKENS<a class="anchor-link" href="#GPT-ARCHITECTURE-PART-7:-GENERATING-TEXT-FROM-OUTPUT-TOKENS">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
Let us implement the token-generation process as follows:
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>Step 1: idx is a (batch, n_tokens) array of indices in the current context</p>
<p>Step 2: Crop current context if it exceeds the supported context size E.g., if LLM supports only 5 tokens, and the
context size is 10 then only the last 5 tokens are used as context</p>
<p>Step 3: Focus only on the last time step, so that (batch, n_token, vocab_size) becomes (batch, vocab_size)</p>
<p>Step 4: probas has shape (batch, vocab_size)</p>
<p>Step 5: idx_next has shape (batch, 1)</p>
<p>Step 6: Append sampled index to the running sequence, where idx has shape (batch, n_tokens+1)</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [154]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">generate_text_simple</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="p">,</span> <span class="n">context_size</span><span class="p">):</span>
    <span class="c1"># idx is (batch, n_tokens) array of indices in the current context</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>

        <span class="c1"># Crop current context if it exceeds the supported context size</span>
        <span class="c1"># E.g., if LLM supports only 5 tokens, and the context size is 10</span>
        <span class="c1"># then only the last 5 tokens are used as context</span>
        <span class="n">idx_cond</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[:,</span> <span class="o">-</span><span class="n">context_size</span><span class="p">:]</span>

        <span class="c1"># Get the predictions</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">idx_cond</span><span class="p">)</span>

        <span class="c1"># Focus only on the last time step</span>
        <span class="c1"># (batch, n_tokens, vocab_size) becomes (batch, vocab_size)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

        <span class="c1"># Apply softmax to get probabilities</span>
        <span class="n">probas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (batch, vocab_size)</span>

        <span class="c1"># Get the idx of the vocab entry with the highest probability value</span>
        <span class="n">idx_next</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probas</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># (batch, 1)</span>

        <span class="c1"># Append sampled index to the running sequence</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="n">idx_next</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (batch, n_tokens+1)</span>

    <span class="k">return</span> <span class="n">idx</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>In the preceeding code, the generate_text_simple function, we use a softmax function to
convert the logits into a probability distribution from which we identify the position with the
highest value via torch.argmax.</p>
<p>The softmax function is monotonic, meaning it preserves
the order of its inputs when transformed into outputs.</p>
<p>So, in practice, the softmax step is
redundant since the position with the highest score in the softmax output tensor is the
same position in the logit tensor.</p>
<p>In other words, we could apply the torch.argmax function
to the logits tensor directly and get identical results.</p>
<p>However, we coded the conversion to
illustrate the full process of transforming logits to probabilities, which can add additional
intuition, such as that the model generates the most likely next token, which is known as
greedy decoding.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-warning">
<p>In the next chapter, when we will implement the GPT training code, we will also
introduce additional sampling techniques where we modify the softmax outputs such that
the model doesn't always select the most likely token, which introduces variability and
creativity in the generated text.</p>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
Let's now try out the generate_text_simple function with the "Hello, I am" context
as model input
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
First, we encode the input context into token IDs:
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [155]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">start_context</span> <span class="o">=</span> <span class="s2">"Hello, I am"</span>
<span class="n">encoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">start_context</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"encoded:"</span><span class="p">,</span> <span class="n">encoded</span><span class="p">)</span>
<span class="n">encoded_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1">#A</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"encoded_tensor.shape:"</span><span class="p">,</span> <span class="n">encoded_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>encoded: [15496, 11, 314, 716]
encoded_tensor.shape: torch.Size([1, 4])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
Next, we put the model into .eval() mode, which disables random components like
dropout, which are only used during training, and use the generate_text_simple function
on the encoded input tensor:
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>We disable dropout since we are not training the model</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [156]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1">#A</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">generate_text_simple</span><span class="p">(</span>
<span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
<span class="n">idx</span><span class="o">=</span><span class="n">encoded_tensor</span><span class="p">,</span>
<span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
<span class="n">context_size</span><span class="o">=</span><span class="n">GPT_CONFIG_124M</span><span class="p">[</span><span class="s2">"context_length"</span><span class="p">]</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Output:"</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Output length:"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])
Output length: 10
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-success">
Using the .decode method of the tokenizer, we can convert the IDs back into text:
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [157]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">decoded_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">decoded_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Hello, I am Featureiman Byeswickattribute argue
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<div class="alert alert-block alert-info">
<p>As we can see, based on the preceding output, the model generated gibberish, which is not
at all coherent text.</p>
<p>What happened?</p>
<p>The reason why the model is unable to produce coherent text is that we haven't trained it yet.</p>
<p>So far, we just
implemented the GPT architecture and initialized a GPT model instance with initial random
weights.</p>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
</html>
